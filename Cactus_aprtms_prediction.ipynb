{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aneta521/cactus-repo/blob/br01/Cactus_aprtms_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7q9xSVn9iNk"
      },
      "source": [
        "# Data load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Syo7wVIIdnBv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "url_train = \"https://raw.githubusercontent.com/valkova-k/cactus-repo/main/assignment09/appartments_train.csv\"\n",
        "url_test  = \"https://raw.githubusercontent.com/valkova-k/cactus-repo/main/assignment09/appartments_test.csv\"\n",
        "\n",
        "train = pd.read_csv(url_train)\n",
        "test  = pd.read_csv(url_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFRL135P-ILn"
      },
      "source": [
        "# Úprava pražských čtvrtí"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "g7A5JWghHSNq",
        "outputId": "252ceb66-df36-4d89-9652-6b9419d0c269"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                    address  praha_num borough_norm\n",
            "0                  Tavolníková, Praha - Krč        NaN          krc\n",
            "1               Pitterova, Praha 3 - Žižkov        3.0       zizkov\n",
            "2              Perucká, Praha 2 - Vinohrady        2.0    vinohrady\n",
            "3                 Brožíkova, Praha - Košíře        NaN       kosire\n",
            "4               Hnězdenská, Praha 8 - Troja        8.0        troja\n",
            "5              Patočkova, Praha 6 - Břevnov        6.0      brevnov\n",
            "6               Okřínecká, Praha 9 - Prosek        9.0       prosek\n",
            "7    Pod stolovou horou, Praha 5 - Jinonice        5.0     jinonice\n",
            "8         Za invalidovnou, Praha 8 - Karlín        8.0       karlin\n",
            "9               Toušeňská, Praha 4 - Lhotka        4.0       lhotka\n",
            "10            Petrská, Praha 1 - Nové Město        1.0   nove mesto\n",
            "11              Sokolovská, Praha 8 - Libeň        8.0        liben\n",
            "12          Pod Krocínkou, Praha - Vysočany        NaN     vysocany\n",
            "13         Nad vinohradem, Praha 4 - Braník        4.0       branik\n",
            "14             Mohylová, Praha 5 - Stodůlky        5.0     stodulky\n",
            "15                 Bernolákova, Praha - Krč        NaN          krc\n",
            "16                         Jitravská, Praha        NaN          NaN\n",
            "17            Bendlova, Praha 9 - Miškovice        9.0    miskovice\n",
            "18          Fráni Šrámka, Praha 5 - Smíchov        5.0      smichov\n",
            "19      Do zahrádek II, Praha 5 - Třebonice        5.0    trebonice\n",
            "20               Janského, Praha - Stodůlky        NaN     stodulky\n",
            "21               Molákova, Praha 8 - Karlín        8.0       karlin\n",
            "22           Pelhřimovská, Praha 4 - Michle        4.0       michle\n",
            "23            Toufarova, Praha 5 - Stodůlky        5.0     stodulky\n",
            "24             Na Okruhu, Praha 4 - Písnice        4.0      pisnice\n",
            "25              Malešická, Praha 3 - Žižkov        3.0       zizkov\n",
            "26           Zvěřinova, Praha 3 - Strašnice        3.0    strasnice\n",
            "27          Chalabalova, Praha 5 - Stodůlky        5.0     stodulky\n",
            "28            Petržílkova, Praha - Stodůlky        NaN     stodulky\n",
            "29       U Výstaviště, Praha 7 - Holešovice        7.0   holesovice\n",
            "30            U sladovny, Praha 5 - Lochkov        5.0      lochkov\n",
            "31              Na kopečku, Praha 8 - Libeň        8.0        liben\n",
            "32            Studentská, Praha 6 - Dejvice        6.0      dejvice\n",
            "33              Sokolovská, Praha 9 - Libeň        9.0        liben\n",
            "34         Za Zelenou liškou, Praha 4 - Krč        4.0          krc\n",
            "35  Vladimíra Kobranova, Praha 5 - Jinonice        5.0     jinonice\n",
            "36          Štěpánská, Praha 1 - Nové Město        1.0   nove mesto\n",
            "37           Jahodová, Praha 10 - Záběhlice       10.0    zabehlice\n",
            "38          Prvního pluku, Praha 8 - Karlín        8.0       karlin\n",
            "39        Pod Altánem, Praha 10 - Strašnice       10.0    strasnice\n",
            "40            Radimovická, Praha 4 - Chodov        4.0       chodov\n",
            "41              Belgická, Praha - Vinohrady        NaN    vinohrady\n",
            "42          Nad Krocínkou, Praha 9 - Prosek        9.0       prosek\n",
            "43             Pod Harfou, Praha - Vysočany        NaN     vysocany\n",
            "44              Veltruská, Praha 9 - Prosek        9.0       prosek\n",
            "45              U hotelu, Praha 6 - Suchdol        6.0      suchdol\n",
            "46               Sochorcova, Praha 4 - Háje        4.0         haje\n",
            "47           Ostrovní, Praha 1 - Nové Město        1.0   nove mesto\n",
            "48                V Štíhlách, Praha 4 - Krč        4.0          krc\n",
            "49                          Spořická, Praha        NaN          NaN\n"
          ]
        }
      ],
      "source": [
        "import unicodedata\n",
        "\n",
        "DASH = r\"[\\-\\u2012-\\u2015\\u2212]\"\n",
        "def normalize_addr(s: str) -> str:\n",
        "    if not isinstance(s, str):\n",
        "        return \"\"\n",
        "    s = re.sub(DASH, \"-\", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "def strip_accents(text):\n",
        "    if isinstance(text, str):\n",
        "        return ''.join(\n",
        "            c for c in unicodedata.normalize('NFKD', text)\n",
        "            if not unicodedata.combining(c)\n",
        "        )\n",
        "    return text\n",
        "\n",
        "# 1) SPECIFICKÝ edge-case: \"Praha - Praha 10\"\n",
        "p_praha_dash_praha_num = re.compile(r\"Praha\\s*-\\s*Praha\\s*(?P<num>\\d{1,2})\\b\", re.IGNORECASE)\n",
        "\n",
        "# 2) standard: \"Praha 10 - Žižkov\" (po pomlčce nesmí začínat \"Praha\")\n",
        "p_num_bor = re.compile(r\"Praha\\s*(?P<num>\\d{1,2})\\s*-\\s*(?P<bor>(?!Praha\\b)[^,]+)\", re.IGNORECASE)\n",
        "\n",
        "# 3) \"Praha - Žižkov\" (bez čísla)\n",
        "p_bor_only = re.compile(r\"Praha\\s*-\\s*(?P<bor>(?!Praha\\b)[^,]+)\", re.IGNORECASE)\n",
        "\n",
        "# 4) fallback na samotné číslo: \"... Praha 10 ...\"\n",
        "p_num_only = re.compile(r\"\\bPraha\\s*(?P<num>\\d{1,2})\\b\", re.IGNORECASE)\n",
        "\n",
        "def extract_from_address(addr: str):\n",
        "    s = normalize_addr(addr)\n",
        "    if not s:\n",
        "        return (np.nan, np.nan)\n",
        "\n",
        "    # A) \"Praha - Praha 10\"  -> num=10, borough = NaN\n",
        "    m = p_praha_dash_praha_num.search(s)\n",
        "    if m:\n",
        "        return (int(m.group(\"num\")), np.nan)\n",
        "\n",
        "    # B) \"Praha 10 - Žižkov\" -> num=10, borough=\"Žižkov\"\n",
        "    m = p_num_bor.search(s)\n",
        "    if m:\n",
        "        num = int(m.group(\"num\"))\n",
        "        bor = m.group(\"bor\").strip()\n",
        "        return (num, bor if bor else np.nan)\n",
        "\n",
        "    # C) \"Praha - Žižkov\" -> num=NaN, borough=\"Žižkov\"\n",
        "    m = p_bor_only.search(s)\n",
        "    if m:\n",
        "        bor = m.group(\"bor\").strip()\n",
        "        return (np.nan, bor if bor else np.nan)\n",
        "\n",
        "    # D) fallback: \"... Praha 10 ...\" -> num=10, borough=NaN\n",
        "    m = p_num_only.search(s)\n",
        "    if m:\n",
        "        return (int(m.group(\"num\")), np.nan)\n",
        "\n",
        "    # E) poslední fallback: část za poslední pomlčkou jako \"čtvrť\"\n",
        "    m = re.search(r\"-\\s*([^,]+)$\", s)\n",
        "    if m:\n",
        "        return (np.nan, m.group(1).strip())\n",
        "\n",
        "    return (np.nan, np.nan)\n",
        "\n",
        "# --- jen TRAIN teď ---\n",
        "train[[\"praha_num\", \"borough\"]] = train[\"address\"].apply(\n",
        "    lambda s: pd.Series(extract_from_address(s))\n",
        ")\n",
        "\n",
        "# Normalizace názvu čtvrti (bez diakritiky a lowercase) – užitečné pro OneHot\n",
        "train[\"borough_norm\"] = train[\"borough\"].apply(strip_accents).str.lower()\n",
        "\n",
        "# Rychlá kontrola výstupu:\n",
        "print(train[[\"address\", \"praha_num\", \"borough_norm\"]].head(50))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6PvYozznUsLf",
        "outputId": "c8ebcbd1-c551-4363-93ee-e09f5ff14a5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imputováno praha_num z borough: 430 řádků\n",
            "Zbývající praha_num NA: 206\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"ambiguous[[\\\"borough_norm\\\", \\\"praha_num\\\", \\\"count\\\", \\\"total\\\", \\\"confidence\\\"]]\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"borough_norm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"nove mesto\",\n          \"vinohrady\",\n          \"liben\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"praha_num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.7416573867739413,\n        \"min\": 1.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1.0,\n          2.0,\n          8.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35,\n        \"min\": 32,\n        \"max\": 110,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          107,\n          110,\n          109\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 56,\n        \"min\": 46,\n        \"max\": 175,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          175,\n          172,\n          145\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"confidence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05556517455230553,\n        \"min\": 0.6114285714285714,\n        \"max\": 0.7517241379310344,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.6114285714285714,\n          0.6395348837209303,\n          0.7517241379310344\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-bcf46ead-23b3-4735-b37e-a6d296bb3a69\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>borough_norm</th>\n",
              "      <th>praha_num</th>\n",
              "      <th>count</th>\n",
              "      <th>total</th>\n",
              "      <th>confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>nove mesto</td>\n",
              "      <td>1.0</td>\n",
              "      <td>107</td>\n",
              "      <td>175</td>\n",
              "      <td>0.611429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>vinohrady</td>\n",
              "      <td>2.0</td>\n",
              "      <td>110</td>\n",
              "      <td>172</td>\n",
              "      <td>0.639535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bubenec</td>\n",
              "      <td>6.0</td>\n",
              "      <td>32</td>\n",
              "      <td>46</td>\n",
              "      <td>0.695652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>zabehlice</td>\n",
              "      <td>10.0</td>\n",
              "      <td>91</td>\n",
              "      <td>127</td>\n",
              "      <td>0.716535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>strizkov</td>\n",
              "      <td>9.0</td>\n",
              "      <td>42</td>\n",
              "      <td>57</td>\n",
              "      <td>0.736842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>liben</td>\n",
              "      <td>8.0</td>\n",
              "      <td>109</td>\n",
              "      <td>145</td>\n",
              "      <td>0.751724</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bcf46ead-23b3-4735-b37e-a6d296bb3a69')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bcf46ead-23b3-4735-b37e-a6d296bb3a69 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bcf46ead-23b3-4735-b37e-a6d296bb3a69');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e2560fee-bf41-456b-b387-e462c2329871\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e2560fee-bf41-456b-b387-e462c2329871')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e2560fee-bf41-456b-b387-e462c2329871 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   borough_norm  praha_num  count  total  confidence\n",
              "50   nove mesto        1.0    107    175    0.611429\n",
              "84    vinohrady        2.0    110    172    0.639535\n",
              "4       bubenec        6.0     32     46    0.695652\n",
              "90    zabehlice       10.0     91    127    0.716535\n",
              "73     strizkov        9.0     42     57    0.736842\n",
              "39        liben        8.0    109    145    0.751724"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# slovnik na cisla Prahy\n",
        "\n",
        "#pár velmi bezpečných ručních přiřazení (volitelné; doplň jen to, co je 100% jasné)\n",
        "manual_map = {\n",
        "    \"zizkov\": 3,\n",
        "    \"karlin\": 8,\n",
        "    \"smichov\": 5,\n",
        "    \"dejvice\": 6,\n",
        "    \"holesovice\": 7,\n",
        "    \"vrsovice\": 10,\n",
        "    \"vysocany\": 9,\n",
        "    \"kobylisy\": 8,\n",
        "    \"bohnice\": 8,\n",
        "    \"prosek\": 9,\n",
        "    \"braník\": 4,  # pozor na čárku vs bez čárky – viz normalize níže, jinak používej 'branik'\n",
        "    \"branik\": 4,\n",
        "    \"krc\": 4,\n",
        "    \"podoli\": 4,\n",
        "    \"modrany\": 12,\n",
        "    \"stodulky\": 13,\n",
        "    \"chodov\": 11,\n",
        "    \"haje\": 11,\n",
        "    \"letnany\": 18,\n",
        "    \"kbely\": 19,\n",
        "    \"horni pocernice\": 20,\n",
        "    \"uhrineves\": 22,\n",
        "    \"radotin\": 16,\n",
        "    \"barrandov\": 5,\n",
        "    \"jinonice\": 5,\n",
        "    \"kosire\": 5,\n",
        "    \"motol\": 5,\n",
        "    \"vokovice\": 6,\n",
        "    \"veleslavin\": 6,\n",
        "    \"brevnov\": 6,\n",
        "    \"suchdol\": 6,\n",
        "    \"nebusice\": 6,\n",
        "    \"troja\": 7,\n",
        "}\n",
        "\n",
        "# 3) datově odhadneme mapování: pro každou čtvrť (borough_norm) vezmi nejčastější praha_num\n",
        "#    + spočítáme míru shody, abychom věděli, jestli je čtvrť jednoznačná\n",
        "grp = (\n",
        "    train.loc[train[\"borough_norm\"].notna() & train[\"praha_num\"].notna(), [\"borough_norm\", \"praha_num\"]]\n",
        "    .groupby(\"borough_norm\")[\"praha_num\"]\n",
        ")\n",
        "\n",
        "mode_map = grp.agg(lambda s: s.mode().iloc[0]).to_dict()\n",
        "counts = grp.value_counts().rename(\"count\").reset_index()  # (borough_norm, praha_num, count)\n",
        "totals = counts.groupby(\"borough_norm\")[\"count\"].sum().rename(\"total\")\n",
        "top = (\n",
        "    counts.sort_values([\"borough_norm\", \"count\"], ascending=[True, False])\n",
        "    .groupby(\"borough_norm\")\n",
        "    .head(1)\n",
        "    .merge(totals, on=\"borough_norm\")\n",
        ")\n",
        "top[\"confidence\"] = top[\"count\"] / top[\"total\"]\n",
        "\n",
        "# jen ty, kde je shoda dost vysoká (např. ≥ 0.85)\n",
        "auto_map = {row[\"borough_norm\"]: int(row[\"praha_num\"]) for _, row in top.iterrows() if row[\"confidence\"] >= 0.85}\n",
        "\n",
        "# 4) finální slovník: ruční mapování má prioritu, pak datové\n",
        "borough_to_praha = {**auto_map, **manual_map}  # manual overrides\n",
        "\n",
        "# 5) imputace praha_num z borough_norm podle slovníku (JEN TRAIN teď)\n",
        "mask_na = train[\"praha_num\"].isna() & train[\"borough_norm\"].notna()\n",
        "train.loc[mask_na, \"praha_num_imputed\"] = train.loc[mask_na, \"borough_norm\"].map(borough_to_praha)\n",
        "# kde se podařilo doplnit, přeneseme do praha_num\n",
        "fill_mask = train[\"praha_num\"].isna() & train[\"praha_num_imputed\"].notna()\n",
        "train.loc[fill_mask, \"praha_num\"] = train.loc[fill_mask, \"praha_num_imputed\"].astype(\"Int64\")\n",
        "train = train.drop(columns=[\"praha_num_imputed\"])\n",
        "\n",
        "# 6) report: kolik se podařilo doplnit a co zůstalo sporné\n",
        "imputed_n = fill_mask.sum()\n",
        "remaining_na = train[\"praha_num\"].isna().sum()\n",
        "print(f\"Imputováno praha_num z borough: {imputed_n} řádků\")\n",
        "print(f\"Zbývající praha_num NA: {remaining_na}\")\n",
        "\n",
        "# čtvrti, které byly nejednoznačné (confidence < 0.85) – můžeš se rozhodnout je přidat ručně\n",
        "ambiguous = top[top[\"confidence\"] < 0.85].sort_values(\"confidence\")\n",
        "ambiguous[[\"borough_norm\", \"praha_num\", \"count\", \"total\", \"confidence\"]].head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6zQ3wSq9wQw"
      },
      "source": [
        "# Pipeline na zpracování dat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrAwih8pUR7K"
      },
      "outputs": [],
      "source": [
        "unique_words = [\n",
        "   \"originální\", \"originálně\", \"originálními\", \"originálním\", \"originálních\",\n",
        "   \"zajímavá\", \"zajímavého\", \"zajímavé\", \"zajímavém\",\n",
        "   \"zajímavým\", \"zajímavých\", \"zajímavě\",\n",
        "   \"zajímavou\", \"zajímavý\", \"atypický\", \"atypicky\", \"neobvyklý\",\n",
        "   \"nevšední\", \"unikátní\", \"unikátním\", \"unikátními\", \"šikovný\"\n",
        " ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBtRSK04z9xM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# ----------- 1) CUSTOM TRANSFORMERS WITH YOUR LOGIC ----------\n",
        "# ===============================================================\n",
        "\n",
        "class BasicImputer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    garden_area, balcony_area, cellar_area → fillna(0)\n",
        "    elevator → Yes/No + fillna, cast\n",
        "    parking → fillna(0)\n",
        "    sentinel imputation for POI columns\n",
        "    \"\"\"\n",
        "    def __init__(self, nearest_cols, impute_val=9999):\n",
        "        self.nearest_cols = nearest_cols\n",
        "        self.impute_val = impute_val\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "\n",
        "        # Simple 0-fill\n",
        "        for col in [\"garden_area\", \"balcony_area\", \"cellar_area\"]:\n",
        "            X[col] = X[col].fillna(0)\n",
        "\n",
        "        # Elevator and parking\n",
        "        X[\"elevator\"] = (\n",
        "            X[\"elevator\"]\n",
        "            .replace({\"Yes\": 1, \"No\": 0})\n",
        "            .fillna(0)\n",
        "            .astype(int)\n",
        "        )\n",
        "        X[\"parking\"] = X[\"parking\"].fillna(0).astype(int)\n",
        "\n",
        "        # POI sentinel imputation\n",
        "        for c in self.nearest_cols:\n",
        "            X[c] = X[c].fillna(self.impute_val)\n",
        "            X[c + \"_exists\"] = (X[c] != self.impute_val).astype(int) # FIX: Changed self.impute_int to self.impute_val\n",
        "\n",
        "        return X\n",
        "\n",
        "\n",
        "class FloorsTransformer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Fix total_floors; add is_ground, is_topfloor, floor_ratio\n",
        "    \"\"\"\n",
        "    def fit(self, X, y=None):\n",
        "        self.med = X[\"total_floors\"].median()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        X[\"total_floors\"] = X[\"total_floors\"].fillna(self.med)\n",
        "        X[\"total_floors\"] = X[[\"total_floors\", \"floor\"]].max(axis=1)\n",
        "\n",
        "        X[\"is_ground\"] = (X[\"floor\"] <= 1).astype(int)\n",
        "        X[\"is_topfloor\"] = (X[\"floor\"] == X[\"total_floors\"]).astype(int)\n",
        "        X[\"floor_ratio\"] = X[\"floor\"] / X[\"total_floors\"]\n",
        "\n",
        "        return X\n",
        "\n",
        "\n",
        "class RoomsLayoutTransformer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Extract number of rooms + is_kk\n",
        "    \"\"\"\n",
        "    def fit(self, X, y=None):\n",
        "        # median for NA rooms\n",
        "        rooms = X[\"layout\"].map(self.extract_rooms)\n",
        "        self.med = rooms.median()\n",
        "        return self\n",
        "\n",
        "    def extract_rooms(self, x):\n",
        "        m = re.match(r\"\\s*(\\d+)\\s*\\+\", str(x))\n",
        "        return int(m.group(1)) if m else np.nan\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        X[\"rooms\"] = X[\"layout\"].map(self.extract_rooms)\n",
        "        X[\"rooms\"] = X[\"rooms\"].fillna(self.med).astype(int)\n",
        "        X[\"is_kk\"] = X[\"layout\"].str.contains(\"kk\", case=False, na=False).astype(int)\n",
        "        return X\n",
        "\n",
        "\n",
        "class DateTransformer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Convert first_seen, last_seen → datetime, compute listing_days\n",
        "    \"\"\"\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        X[\"first_seen_dt\"] = pd.to_datetime(X[\"first_seen\"], errors=\"coerce\")\n",
        "        X[\"last_seen_dt\"] = pd.to_datetime(X[\"last_seen\"], errors=\"coerce\")\n",
        "        X[\"listing_days\"] = (X[\"last_seen_dt\"] - X[\"first_seen_dt\"]).dt.days\n",
        "        X[\"listing_days\"] = X[\"listing_days\"].clip(lower=0).fillna(0)\n",
        "        return X\n",
        "\n",
        "\n",
        "# helper functions for borough extraction\n",
        "DASH = r\"[\\-\\u2012-\\u2015\\u2212]\"\n",
        "p_praha_dash_praha_num = re.compile(r\"Praha\\s*-\\s*Praha\\s*(?P<num>\\d{1,2})\\b\", re.IGNORECASE)\n",
        "p_num_bor = re.compile(r\"Praha\\s*(?P<num>\\d{1,2})\\s*-\\s*(?P<bor>(?!Praha\\b)[^,]+)\", re.IGNORECASE)\n",
        "p_bor_only = re.compile(r\"Praha\\s*-\\s*(?P<bor>(?!Praha\\b)[^,]+)\", re.IGNORECASE)\n",
        "p_num_only = re.compile(r\"\\bPraha\\s*(?P<num>\\d{1,2})\\b\", re.IGNORECASE)\n",
        "\n",
        "def normalize_addr(s: str) -> str:\n",
        "    if not isinstance(s, str): return \"\"\n",
        "    s = re.sub(DASH, \"-\", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "def strip_accents(text):\n",
        "    if isinstance(text, str):\n",
        "        return ''.join(c for c in unicodedata.normalize('NFKD', text)\n",
        "                       if not unicodedata.combining(c))\n",
        "    return text\n",
        "\n",
        "def extract_from_address(addr: str):\n",
        "    s = normalize_addr(addr)\n",
        "    if not s:\n",
        "        return (np.nan, np.nan)\n",
        "\n",
        "    m = p_praha_dash_praha_num.search(s)\n",
        "    if m: return int(m.group(\"num\")), np.nan\n",
        "\n",
        "    m = p_num_bor.search(s)\n",
        "    if m: return int(m.group(\"num\")), m.group(\"bor\").strip()\n",
        "\n",
        "    m = p_bor_only.search(s)\n",
        "    if m: return np.nan, m.group(\"bor\").strip()\n",
        "\n",
        "    m = p_num_only.search(s)\n",
        "    if m: return int(m.group(\"num\")), np.nan\n",
        "\n",
        "    m = re.search(r\"-\\s*([^,]+)$\", s)\n",
        "    if m: return np.nan, m.group(1).strip()\n",
        "\n",
        "    return (np.nan, np.nan)\n",
        "\n",
        "\n",
        "class BoroughTransformer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Extract praha_num, borough_norm & map missing praha_num using the dictionary.\n",
        "    \"\"\"\n",
        "    def __init__(self, borough_to_praha: dict):\n",
        "        self.borough_to_praha = borough_to_praha\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "\n",
        "        tmp = X[\"address\"].apply(lambda s: pd.Series(extract_from_address(s)))\n",
        "        X[\"praha_num\"] = tmp.iloc[:, 0]\n",
        "        X[\"borough\"] = tmp.iloc[:, 1]\n",
        "\n",
        "        X[\"borough_norm\"] = X[\"borough\"].apply(strip_accents).str.lower()\n",
        "\n",
        "        mask = X[\"praha_num\"].isna() & X[\"borough_norm\"].notna()\n",
        "        X.loc[mask, \"praha_num\"] = X.loc[mask, \"borough_norm\"].map(self.borough_to_praha)\n",
        "\n",
        "        return X\n",
        "\n",
        "class UniqueDescriptionTransformer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Adds a 'unique_in_desc' column based on whether certain unique words are present in the 'text' column.\n",
        "    \"\"\"\n",
        "    def __init__(self, unique_words):\n",
        "        self.unique_words = unique_words\n",
        "        self.combined_regex = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        # Pre-compile the regex pattern during fit for efficiency\n",
        "        # Use a non-capturing group (?:...) to avoid UserWarning about match groups with str.contains\n",
        "        combined_pattern = r'\\b(?:' + '|'.join(re.escape(word) for word in self.unique_words) + r')\\b'\n",
        "        self.combined_regex = re.compile(combined_pattern, re.IGNORECASE)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        if self.combined_regex is None:\n",
        "            raise RuntimeError(\"Transformer has not been fitted. Call fit() before transform().\")\n",
        "\n",
        "        # Create the new boolean column 'unique_in_desc'\n",
        "        # It's important to use .astype(str) as 'text' column might have NaNs\n",
        "        X['unique_in_desc'] = X['text'].astype(str).str.contains(self.combined_regex, na=False)\n",
        "        return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KBl62I0DaQk"
      },
      "source": [
        "# Pipeline na model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4d1a8f14"
      },
      "outputs": [],
      "source": [
        "def make_full_pipeline(borough_to_praha, unique_words):\n",
        "    nearest_cols = [\n",
        "        \"poi_doctors_nearest\",\n",
        "        \"poi_leisure_time_nearest\",\n",
        "        \"poi_school_kindergarten_nearest\",\n",
        "        \"poi_transport_nearest\",\n",
        "        \"poi_grocery_nearest\",\n",
        "        \"poi_restaurant_nearest\",\n",
        "    ]\n",
        "\n",
        "    preprocessing = Pipeline([\n",
        "        (\"basic\", BasicImputer(nearest_cols)),\n",
        "        (\"floors\", FloorsTransformer()),\n",
        "        (\"rooms\", RoomsLayoutTransformer()),\n",
        "        (\"dates\", DateTransformer()),\n",
        "        (\"boroughs\", BoroughTransformer(borough_to_praha)),\n",
        "        (\"unique_desc\", UniqueDescriptionTransformer(unique_words)), # Add the new transformer\n",
        "    ])\n",
        "\n",
        "    # after your custom steps, apply a ColumnTransformer\n",
        "    numeric_cols = [\n",
        "        \"garden_area\", \"balcony_area\", \"cellar_area\",\n",
        "        \"elevator\", \"parking\", \"is_ground\", \"is_topfloor\",\n",
        "        \"floor_ratio\", \"rooms\", \"is_kk\", \"listing_days\",\n",
        "        \"praha_num\", \"unique_in_desc\"\n",
        "    ] + nearest_cols + [c+\"_exists\" for c in nearest_cols]\n",
        "\n",
        "    categorical_cols = [\"borough_norm\"]\n",
        "\n",
        "    ct = ColumnTransformer([\n",
        "        (\"num\", SimpleImputer(strategy=\"median\"), numeric_cols),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
        "    ])\n",
        "\n",
        "    model = RandomForestRegressor(n_estimators=500, random_state=42)\n",
        "\n",
        "    full_pipe = Pipeline([\n",
        "        (\"prep\", preprocessing),\n",
        "        (\"ct\", ct),\n",
        "        (\"model\", model),\n",
        "    ])\n",
        "\n",
        "    return full_pipe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbBuag5vDTuo"
      },
      "source": [
        "# Finální validace\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "563f48e4",
        "outputId": "36db4018-63e7-4a5e-cdb4-20ceb33b5a3a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validation MAPE scores: [0.16305206 0.16653931 0.16346487 0.17069403 0.17058291]\n",
            "Mean CV MAPE: 0.1669\n",
            "Std CV MAPE: 0.0033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import make_scorer, mean_absolute_percentage_error\n",
        "\n",
        "def mape_scorer(y_true, y_pred):\n",
        "    return mean_absolute_percentage_error(y_true, y_pred)\n",
        "\n",
        "mape = make_scorer(mape_scorer, greater_is_better=False) # greater_is_better=False because lower MAPE is better\n",
        "\n",
        "pipeline = make_full_pipeline(borough_to_praha, unique_words)\n",
        "\n",
        "X = train.drop(columns=[\"price\"])\n",
        "y = train[\"price\"]\n",
        "\n",
        "# Perform cross-validation with MAPE\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores_mape = cross_val_score(pipeline, X, y, cv=kf, scoring=mape)\n",
        "cv_mape = -cv_scores_mape # Multiply by -1 because make_scorer returns negative scores for metrics where lower is better\n",
        "\n",
        "print(f\"Cross-validation MAPE scores: {cv_mape}\")\n",
        "print(f\"Mean CV MAPE: {np.mean(cv_mape):.4f}\")\n",
        "print(f\"Std CV MAPE: {np.std(cv_mape):.4f}\")\n",
        "\n",
        "# Fit the pipeline on the full training data and make predictions on the test set\n",
        "pipeline.fit(X, y)\n",
        "preds = pipeline.predict(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAiGq9arrbzI"
      },
      "source": [
        "These scores indicate that, on average, the model's predictions deviate by about 16.70% from the actual values, with a standard deviation of 0.33% across the folds. This suggests a relatively consistent performance across different subsets of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e30a0781"
      },
      "source": [
        "```python\n",
        "def make_full_pipeline(model_estimator, borough_to_praha, unique_words):\n",
        "    nearest_cols = [\n",
        "        \"poi_doctors_nearest\",\n",
        "        \"poi_leisure_time_nearest\",\n",
        "        \"poi_school_kindergarten_nearest\",\n",
        "        \"poi_transport_nearest\",\n",
        "        \"poi_grocery_nearest\",\n",
        "        \"poi_restaurant_nearest\",\n",
        "    ]\n",
        "\n",
        "    preprocessing = Pipeline([\n",
        "        (\"basic\", BasicImputer(nearest_cols)),\n",
        "        (\"floors\", FloorsTransformer()),\n",
        "        (\"rooms\", RoomsLayoutTransformer()),\n",
        "        (\"dates\", DateTransformer()),\n",
        "        (\"boroughs\", BoroughTransformer(borough_to_praha)),\n",
        "        (\"unique_desc\", UniqueDescriptionTransformer(unique_words)), # Add the new transformer\n",
        "    ])\n",
        "\n",
        "    # after your custom steps, apply a ColumnTransformer\n",
        "    numeric_cols = [\n",
        "        \"garden_area\", \"balcony_area\", \"cellar_area\",\n",
        "        \"elevator\", \"parking\", \"is_ground\", \"is_topfloor\",\n",
        "        \"floor_ratio\", \"rooms\", \"is_kk\", \"listing_days\",\n",
        "        \"praha_num\", \"unique_in_desc\"\n",
        "    ] + nearest_cols + [c+\"_exists\" for c in nearest_cols]\n",
        "\n",
        "    categorical_cols = [\"borough_norm\"]\n",
        "\n",
        "    ct = ColumnTransformer([\n",
        "        (\"num\", SimpleImputer(strategy=\"median\"), numeric_cols),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
        "    ])\n",
        "\n",
        "    full_pipe = Pipeline([\n",
        "        (\"prep\", preprocessing),\n",
        "        (\"ct\", ct),\n",
        "        (\"model\", model_estimator),  # Use the model_estimator passed as argument\n",
        "    ])\n",
        "\n",
        "    return full_pipe\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "608c91f6"
      },
      "outputs": [],
      "source": [
        "def make_full_pipeline(model_estimator, borough_to_praha, unique_words):\n",
        "    nearest_cols = [\n",
        "        \"poi_doctors_nearest\",\n",
        "        \"poi_leisure_time_nearest\",\n",
        "        \"poi_school_kindergarten_nearest\",\n",
        "        \"poi_transport_nearest\",\n",
        "        \"poi_grocery_nearest\",\n",
        "        \"poi_restaurant_nearest\",\n",
        "    ]\n",
        "\n",
        "    preprocessing = Pipeline([\n",
        "        (\"basic\", BasicImputer(nearest_cols)),\n",
        "        (\"floors\", FloorsTransformer()),\n",
        "        (\"rooms\", RoomsLayoutTransformer()),\n",
        "        (\"dates\", DateTransformer()),\n",
        "        (\"boroughs\", BoroughTransformer(borough_to_praha)),\n",
        "        (\"unique_desc\", UniqueDescriptionTransformer(unique_words)), # Add the new transformer\n",
        "    ])\n",
        "\n",
        "    # after your custom steps, apply a ColumnTransformer\n",
        "    numeric_cols = [\n",
        "        \"garden_area\", \"balcony_area\", \"cellar_area\",\n",
        "        \"elevator\", \"parking\", \"is_ground\", \"is_topfloor\",\n",
        "        \"floor_ratio\", \"rooms\", \"is_kk\", \"listing_days\",\n",
        "        \"praha_num\", \"unique_in_desc\"\n",
        "    ] + nearest_cols + [c+\"_exists\" for c in nearest_cols]\n",
        "\n",
        "    categorical_cols = [\"borough_norm\"]\n",
        "\n",
        "    ct = ColumnTransformer([\n",
        "        (\"num\", SimpleImputer(strategy=\"median\"), numeric_cols),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
        "    ])\n",
        "\n",
        "    full_pipe = Pipeline([\n",
        "        (\"prep\", preprocessing),\n",
        "        (\"ct\", ct),\n",
        "        (\"model\", model_estimator), # Use the passed model_estimator\n",
        "    ])\n",
        "\n",
        "    return full_pipe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47f856a8"
      },
      "outputs": [],
      "source": [
        "def make_full_pipeline(model_estimator, borough_to_praha, unique_words):\n",
        "    nearest_cols = [\n",
        "        \"poi_doctors_nearest\",\n",
        "        \"poi_leisure_time_nearest\",\n",
        "        \"poi_school_kindergarten_nearest\",\n",
        "        \"poi_transport_nearest\",\n",
        "        \"poi_grocery_nearest\",\n",
        "        \"poi_restaurant_nearest\",\n",
        "    ]\n",
        "\n",
        "    preprocessing = Pipeline([\n",
        "        (\"basic\", BasicImputer(nearest_cols)),\n",
        "        (\"floors\", FloorsTransformer()),\n",
        "        (\"rooms\", RoomsLayoutTransformer()),\n",
        "        (\"dates\", DateTransformer()),\n",
        "        (\"boroughs\", BoroughTransformer(borough_to_praha)),\n",
        "        (\"unique_desc\", UniqueDescriptionTransformer(unique_words)), # Add the new transformer\n",
        "    ])\n",
        "\n",
        "    # after your custom steps, apply a ColumnTransformer\n",
        "    numeric_cols = [\n",
        "        \"garden_area\", \"balcony_area\", \"cellar_area\",\n",
        "        \"elevator\", \"parking\", \"is_ground\", \"is_topfloor\",\n",
        "        \"floor_ratio\", \"rooms\", \"is_kk\", \"listing_days\",\n",
        "        \"praha_num\", \"unique_in_desc\"\n",
        "    ] + nearest_cols + [c+\"_exists\" for c in nearest_cols]\n",
        "\n",
        "    categorical_cols = [\"borough_norm\"]\n",
        "\n",
        "    ct = ColumnTransformer([\n",
        "        (\"num\", SimpleImputer(strategy=\"median\"), numeric_cols),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
        "    ])\n",
        "\n",
        "    full_pipe = Pipeline([\n",
        "        (\"prep\", preprocessing),\n",
        "        (\"ct\", ct),\n",
        "        (\"model\", model_estimator), # Use the passed model_estimator\n",
        "    ])\n",
        "\n",
        "    return full_pipe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b670e3d2"
      },
      "source": [
        "## Select and Prepare New Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95aae356",
        "outputId": "e3dc59d5-fca4-4099-948e-ec40b22d7c92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Regression models instantiated successfully.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "# Instantiate models\n",
        "# RandomForestRegressor is already used, but we'll re-instantiate for consistency.\n",
        "model_rf = RandomForestRegressor(random_state=42)\n",
        "model_gbr = GradientBoostingRegressor(random_state=42)\n",
        "model_lr = LinearRegression()\n",
        "model_xgb = XGBRegressor(random_state=42)\n",
        "model_lgbm = LGBMRegressor(random_state=42)\n",
        "\n",
        "print(\"Regression models instantiated successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a046f6fe"
      },
      "source": [
        "## Train and Evaluate Each Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6f52dca"
      },
      "outputs": [],
      "source": [
        "models = [\n",
        "    (\"RandomForestRegressor\", model_rf),\n",
        "    (\"GradientBoostingRegressor\", model_gbr),\n",
        "    (\"LinearRegression\", model_lr),\n",
        "    (\"XGBRegressor\", model_xgb),\n",
        "    (\"LGBMRegressor\", model_lgbm),\n",
        "]\n",
        "\n",
        "results = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1cd6663",
        "outputId": "7c30522c-87ec-44f1-c4b5-baf4c74d6e61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating RandomForestRegressor...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Mean CV MAPE: 0.1680\n",
            "  Std CV MAPE: 0.0038\n",
            "\n",
            "Evaluating GradientBoostingRegressor...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Mean CV MAPE: 0.1743\n",
            "  Std CV MAPE: 0.0036\n",
            "\n",
            "Evaluating LinearRegression...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Mean CV MAPE: 0.2006\n",
            "  Std CV MAPE: 0.0049\n",
            "\n",
            "Evaluating XGBRegressor...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Mean CV MAPE: 0.1640\n",
            "  Std CV MAPE: 0.0045\n",
            "\n",
            "Evaluating LGBMRegressor...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001185 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1946\n",
            "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 71\n",
            "[LightGBM] [Info] Start training from score 9627962.017750\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001404 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1952\n",
            "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 73\n",
            "[LightGBM] [Info] Start training from score 9556175.422500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000670 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1952\n",
            "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 73\n",
            "[LightGBM] [Info] Start training from score 9602417.782250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000688 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1949\n",
            "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 73\n",
            "[LightGBM] [Info] Start training from score 9603492.210500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001351 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1942\n",
            "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 71\n",
            "[LightGBM] [Info] Start training from score 9612858.139000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-428162344.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  .replace({\"Yes\": 1, \"No\": 0})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Mean CV MAPE: 0.1603\n",
            "  Std CV MAPE: 0.0031\n",
            "\n",
            "--- All Model Results ---\n",
            "RandomForestRegressor: Mean MAPE = 0.1680, Std MAPE = 0.0038\n",
            "GradientBoostingRegressor: Mean MAPE = 0.1743, Std MAPE = 0.0036\n",
            "LinearRegression: Mean MAPE = 0.2006, Std MAPE = 0.0049\n",
            "XGBRegressor: Mean MAPE = 0.1640, Std MAPE = 0.0045\n",
            "LGBMRegressor: Mean MAPE = 0.1603, Std MAPE = 0.0031\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "for name, model in models:\n",
        "    print(f\"\\nEvaluating {name}...\")\n",
        "\n",
        "    # Create the full pipeline for the current model\n",
        "    current_pipeline = make_full_pipeline(model, borough_to_praha, unique_words)\n",
        "\n",
        "    # Perform cross-validation with MAPE\n",
        "    cv_scores_mape = cross_val_score(current_pipeline, X, y, cv=kf, scoring=mape, error_score='raise')\n",
        "    cv_mape = -cv_scores_mape # Multiply by -1 because make_scorer returns negative scores for metrics where lower is better\n",
        "\n",
        "    mean_mape = np.mean(cv_mape)\n",
        "    std_mape = np.std(cv_mape)\n",
        "\n",
        "    results[name] = {\"mean_mape\": mean_mape, \"std_mape\": std_mape}\n",
        "\n",
        "    print(f\"  Mean CV MAPE: {mean_mape:.4f}\")\n",
        "    print(f\"  Std CV MAPE: {std_mape:.4f}\")\n",
        "\n",
        "print(\"\\n--- All Model Results ---\")\n",
        "for name, metrics in results.items():\n",
        "    print(f\"{name}: Mean MAPE = {metrics['mean_mape']:.4f}, Std MAPE = {metrics['std_mape']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa416920"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# ----------- 1) CUSTOM TRANSFORMERS WITH YOUR LOGIC ----------\n",
        "# ===============================================================\n",
        "\n",
        "class BasicImputer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    garden_area, balcony_area, cellar_area → fillna(0)\n",
        "    elevator → Yes/No + fillna, cast\n",
        "    parking → fillna(0)\n",
        "    sentinel imputation for POI columns\n",
        "    \"\"\"\n",
        "    def __init__(self, nearest_cols, impute_val=9999):\n",
        "        self.nearest_cols = nearest_cols\n",
        "        self.impute_val = impute_val\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "\n",
        "        # Simple 0-fill\n",
        "        for col in [\"garden_area\", \"balcony_area\", \"cellar_area\"]:\n",
        "            X[col] = X[col].fillna(0)\n",
        "\n",
        "        # Elevator and parking\n",
        "        # Use .map() instead of .replace() for explicit mapping to avoid FutureWarning\n",
        "        X[\"elevator\"] = (\n",
        "            X[\"elevator\"]\n",
        "            .map({\"Yes\": 1, \"No\": 0})\n",
        "            .fillna(0)\n",
        "            .astype(int)\n",
        "        )\n",
        "        X[\"parking\"] = X[\"parking\"].fillna(0).astype(int)\n",
        "\n",
        "        # POI sentinel imputation\n",
        "        for c in self.nearest_cols:\n",
        "            X[c] = X[c].fillna(self.impute_val)\n",
        "            X[c + \"_exists\"] = (X[c] != self.impute_val).astype(int)\n",
        "\n",
        "        return X\n",
        "\n",
        "\n",
        "class FloorsTransformer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Fix total_floors; add is_ground, is_topfloor, floor_ratio\n",
        "    \"\"\"\n",
        "    def fit(self, X, y=None):\n",
        "        self.med = X[\"total_floors\"].median()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        X[\"total_floors\"] = X[\"total_floors\"].fillna(self.med)\n",
        "        X[\"total_floors\"] = X[[\"total_floors\", \"floor\"]].max(axis=1)\n",
        "\n",
        "        X[\"is_ground\"] = (X[\"floor\"] <= 1).astype(int)\n",
        "        X[\"is_topfloor\"] = (X[\"floor\"] == X[\"total_floors\"]).astype(int)\n",
        "        X[\"floor_ratio\"] = X[\"floor\"] / X[\"total_floors\"]\n",
        "\n",
        "        return X\n",
        "\n",
        "\n",
        "class RoomsLayoutTransformer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Extract number of rooms + is_kk\n",
        "    \"\"\"\n",
        "    def fit(self, X, y=None):\n",
        "        # median for NA rooms\n",
        "        rooms = X[\"layout\"].map(self.extract_rooms)\n",
        "        self.med = rooms.median()\n",
        "        return self\n",
        "\n",
        "    def extract_rooms(self, x):\n",
        "        m = re.match(r\"\\s*(\\d+)\\s*\\+\", str(x))\n",
        "        return int(m.group(1)) if m else np.nan\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        X[\"rooms\"] = X[\"layout\"].map(self.extract_rooms)\n",
        "        X[\"rooms\"] = X[\"rooms\"].fillna(self.med).astype(int)\n",
        "        X[\"is_kk\"] = X[\"layout\"].str.contains(\"kk\", case=False, na=False).astype(int)\n",
        "        return X\n",
        "\n",
        "\n",
        "class DateTransformer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Convert first_seen, last_seen → datetime, compute listing_days\n",
        "    \"\"\"\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        X[\"first_seen_dt\"] = pd.to_datetime(X[\"first_seen\"], errors=\"coerce\")\n",
        "        X[\"last_seen_dt\"] = pd.to_datetime(X[\"last_seen\"], errors=\"coerce\")\n",
        "        X[\"listing_days\"] = (X[\"last_seen_dt\"] - X[\"first_seen_dt\"]).dt.days\n",
        "        X[\"listing_days\"] = X[\"listing_days\"].clip(lower=0).fillna(0)\n",
        "        return X\n",
        "\n",
        "\n",
        "# helper functions for borough extraction\n",
        "DASH = r\"[\\-\\u2012-\\u2015\\u2212]\"\n",
        "p_praha_dash_praha_num = re.compile(r\"Praha\\s*-\\s*Praha\\s*(?P<num>\\d{1,2})\\b\", re.IGNORECASE)\n",
        "p_num_bor = re.compile(r\"Praha\\s*(?P<num>\\d{1,2})\\s*-\\s*(?P<bor>(?!Praha\\b)[^,]+)\", re.IGNORECASE)\n",
        "p_bor_only = re.compile(r\"Praha\\s*-\\s*(?P<bor>(?!Praha\\b)[^,]+)\", re.IGNORECASE)\n",
        "p_num_only = re.compile(r\"\\bPraha\\s*(?P<num>\\d{1,2})\\b\", re.IGNORECASE)\n",
        "\n",
        "def normalize_addr(s: str) -> str:\n",
        "    if not isinstance(s, str): return \"\"\n",
        "    s = re.sub(DASH, \"-\", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "def strip_accents(text):\n",
        "    if isinstance(text, str):\n",
        "        return ''.join(c for c in unicodedata.normalize('NFKD', text)\n",
        "                       if not unicodedata.combining(c))\n",
        "    return text\n",
        "\n",
        "def extract_from_address(addr: str):\n",
        "    s = normalize_addr(addr)\n",
        "    if not s:\n",
        "        return (np.nan, np.nan)\n",
        "\n",
        "    m = p_praha_dash_praha_num.search(s)\n",
        "    if m: return int(m.group(\"num\")), np.nan\n",
        "\n",
        "    m = p_num_bor.search(s)\n",
        "    if m: return int(m.group(\"num\")), m.group(\"bor\").strip()\n",
        "\n",
        "    m = p_bor_only.search(s)\n",
        "    if m: return np.nan, m.group(\"bor\").strip()\n",
        "\n",
        "    m = p_num_only.search(s)\n",
        "    if m: return int(m.group(\"num\")), np.nan\n",
        "\n",
        "    m = re.search(r\"-\\s*([^,]+)$\", s)\n",
        "    if m: return np.nan, m.group(1).strip()\n",
        "\n",
        "    return (np.nan, np.nan)\n",
        "\n",
        "\n",
        "class BoroughTransformer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Extract praha_num, borough_norm & map missing praha_num using the dictionary.\n",
        "    \"\"\"\n",
        "    def __init__(self, borough_to_praha: dict):\n",
        "        self.borough_to_praha = borough_to_praha\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "\n",
        "        tmp = X[\"address\"].apply(lambda s: pd.Series(extract_from_address(s)))\n",
        "        X[\"praha_num\"] = tmp.iloc[:, 0]\n",
        "        X[\"borough\"] = tmp.iloc[:, 1]\n",
        "\n",
        "        X[\"borough_norm\"] = X[\"borough\"].apply(strip_accents).str.lower()\n",
        "\n",
        "        mask = X[\"praha_num\"].isna() & X[\"borough_norm\"].notna()\n",
        "        X.loc[mask, \"praha_num\"] = X.loc[mask, \"borough_norm\"].map(self.borough_to_praha)\n",
        "\n",
        "        return X\n",
        "\n",
        "class UniqueDescriptionTransformer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Adds a 'unique_in_desc' column based on whether certain unique words are present in the 'text' column.\n",
        "    \"\"\"\n",
        "    def __init__(self, unique_words):\n",
        "        self.unique_words = unique_words\n",
        "        self.combined_regex = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        # Pre-compile the regex pattern during fit for efficiency\n",
        "        # Use a non-capturing group (?:...) to avoid UserWarning about match groups with str.contains\n",
        "        combined_pattern = r'\\b(?:' + '|'.join(re.escape(word) for word in self.unique_words) + r')\\b'\n",
        "        self.combined_regex = re.compile(combined_pattern, re.IGNORECASE)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        if self.combined_regex is None:\n",
        "            raise RuntimeError(\"Transformer has not been fitted. Call fit() before transform().\")\n",
        "\n",
        "        # Create the new boolean column 'unique_in_desc'\n",
        "        # It's important to use .astype(str) as 'text' column might have NaNs\n",
        "        X['unique_in_desc'] = X['text'].astype(str).str.contains(self.combined_regex, na=False)\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8cd9961",
        "outputId": "1a8287ac-cefa-47fb-c0f4-b1c9a6b9b225"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating RandomForestRegressor...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Mean CV MAPE: 0.1680\n",
            "  Std CV MAPE: 0.0038\n",
            "\n",
            "Evaluating GradientBoostingRegressor...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Mean CV MAPE: 0.1743\n",
            "  Std CV MAPE: 0.0036\n",
            "\n",
            "Evaluating LinearRegression...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Mean CV MAPE: 0.2006\n",
            "  Std CV MAPE: 0.0049\n",
            "\n",
            "Evaluating XGBRegressor...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Mean CV MAPE: 0.1640\n",
            "  Std CV MAPE: 0.0045\n",
            "\n",
            "Evaluating LGBMRegressor...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000658 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1946\n",
            "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 71\n",
            "[LightGBM] [Info] Start training from score 9627962.017750\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000688 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1952\n",
            "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 73\n",
            "[LightGBM] [Info] Start training from score 9556175.422500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000944 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1952\n",
            "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 73\n",
            "[LightGBM] [Info] Start training from score 9602417.782250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001475 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1949\n",
            "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 73\n",
            "[LightGBM] [Info] Start training from score 9603492.210500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001380 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1942\n",
            "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 71\n",
            "[LightGBM] [Info] Start training from score 9612858.139000\n",
            "  Mean CV MAPE: 0.1603\n",
            "  Std CV MAPE: 0.0031\n",
            "\n",
            "--- All Model Results ---\n",
            "RandomForestRegressor: Mean MAPE = 0.1680, Std MAPE = 0.0038\n",
            "GradientBoostingRegressor: Mean MAPE = 0.1743, Std MAPE = 0.0036\n",
            "LinearRegression: Mean MAPE = 0.2006, Std MAPE = 0.0049\n",
            "XGBRegressor: Mean MAPE = 0.1640, Std MAPE = 0.0045\n",
            "LGBMRegressor: Mean MAPE = 0.1603, Std MAPE = 0.0031\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "for name, model in models:\n",
        "    print(f\"\\nEvaluating {name}...\")\n",
        "\n",
        "    # Create the full pipeline for the current model\n",
        "    current_pipeline = make_full_pipeline(model, borough_to_praha, unique_words)\n",
        "\n",
        "    # Perform cross-validation with MAPE\n",
        "    cv_scores_mape = cross_val_score(current_pipeline, X, y, cv=kf, scoring=mape, error_score='raise')\n",
        "    cv_mape = -cv_scores_mape # Multiply by -1 because make_scorer returns negative scores for metrics where lower is better\n",
        "\n",
        "    mean_mape = np.mean(cv_mape)\n",
        "    std_mape = np.std(cv_mape)\n",
        "\n",
        "    results[name] = {\"mean_mape\": mean_mape, \"std_mape\": std_mape}\n",
        "\n",
        "    print(f\"  Mean CV MAPE: {mean_mape:.4f}\")\n",
        "    print(f\"  Std CV MAPE: {std_mape:.4f}\")\n",
        "\n",
        "print(\"\\n--- All Model Results ---\")\n",
        "for name, metrics in results.items():\n",
        "    print(f\"{name}: Mean MAPE = {metrics['mean_mape']:.4f}, Std MAPE = {metrics['std_mape']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f89c63d5"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous output showed `FutureWarning` messages from `sklearn.pipeline` indicating that the pipeline instance was not fitted yet, even though `cross_val_score` handles fitting internally. To suppress these informational warnings and clean up the output, I will use Python's `warnings` module to filter them specifically for the `sklearn.pipeline` module.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bad2299",
        "outputId": "128894b2-9838-4d15-be55-74e76d1597f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating RandomForestRegressor...\n",
            "  Mean CV MAPE: 0.1680\n",
            "  Std CV MAPE: 0.0038\n",
            "\n",
            "Evaluating GradientBoostingRegressor...\n",
            "  Mean CV MAPE: 0.1743\n",
            "  Std CV MAPE: 0.0036\n",
            "\n",
            "Evaluating LinearRegression...\n",
            "  Mean CV MAPE: 0.2006\n",
            "  Std CV MAPE: 0.0049\n",
            "\n",
            "Evaluating XGBRegressor...\n",
            "  Mean CV MAPE: 0.1640\n",
            "  Std CV MAPE: 0.0045\n",
            "\n",
            "Evaluating LGBMRegressor...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000643 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1946\n",
            "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 71\n",
            "[LightGBM] [Info] Start training from score 9627962.017750\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000950 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1952\n",
            "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 73\n",
            "[LightGBM] [Info] Start training from score 9556175.422500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002150 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1952\n",
            "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 73\n",
            "[LightGBM] [Info] Start training from score 9602417.782250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000716 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1949\n",
            "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 73\n",
            "[LightGBM] [Info] Start training from score 9603492.210500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000967 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1942\n",
            "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 71\n",
            "[LightGBM] [Info] Start training from score 9612858.139000\n",
            "  Mean CV MAPE: 0.1603\n",
            "  Std CV MAPE: 0.0031\n",
            "\n",
            "--- All Model Results ---\n",
            "RandomForestRegressor: Mean MAPE = 0.1680, Std MAPE = 0.0038\n",
            "GradientBoostingRegressor: Mean MAPE = 0.1743, Std MAPE = 0.0036\n",
            "LinearRegression: Mean MAPE = 0.2006, Std MAPE = 0.0049\n",
            "XGBRegressor: Mean MAPE = 0.1640, Std MAPE = 0.0045\n",
            "LGBMRegressor: Mean MAPE = 0.1603, Std MAPE = 0.0031\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "\n",
        "for name, model in models:\n",
        "    print(f\"\\nEvaluating {name}...\")\n",
        "\n",
        "    # Create the full pipeline for the current model\n",
        "    current_pipeline = make_full_pipeline(model, borough_to_praha, unique_words)\n",
        "\n",
        "    # Perform cross-validation with MAPE, suppressing FutureWarnings from sklearn.pipeline\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter(\"ignore\", FutureWarning)\n",
        "        cv_scores_mape = cross_val_score(current_pipeline, X, y, cv=kf, scoring=mape, error_score='raise')\n",
        "    cv_mape = -cv_scores_mape # Multiply by -1 because make_scorer returns negative scores for metrics where lower is better\n",
        "\n",
        "    mean_mape = np.mean(cv_mape)\n",
        "    std_mape = np.std(cv_mape)\n",
        "\n",
        "    results[name] = {\"mean_mape\": mean_mape, \"std_mape\": std_mape}\n",
        "\n",
        "    print(f\"  Mean CV MAPE: {mean_mape:.4f}\")\n",
        "    print(f\"  Std CV MAPE: {std_mape:.4f}\")\n",
        "\n",
        "print(\"\\n--- All Model Results ---\")\n",
        "for name, metrics in results.items():\n",
        "    print(f\"{name}: Mean MAPE = {metrics['mean_mape']:.4f}, Std MAPE = {metrics['std_mape']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0f008b5",
        "outputId": "cdd1ff82-72e3-438f-ac0c-0f4032fb21a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating RandomForestRegressor...\n",
            "  Mean CV MAPE: 0.1680\n",
            "  Std CV MAPE: 0.0038\n",
            "\n",
            "Evaluating GradientBoostingRegressor...\n",
            "  Mean CV MAPE: 0.1743\n",
            "  Std CV MAPE: 0.0036\n",
            "\n",
            "Evaluating LinearRegression...\n",
            "  Mean CV MAPE: 0.2006\n",
            "  Std CV MAPE: 0.0049\n",
            "\n",
            "Evaluating XGBRegressor...\n",
            "  Mean CV MAPE: 0.1640\n",
            "  Std CV MAPE: 0.0045\n",
            "\n",
            "Evaluating LGBMRegressor...\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001423 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1946\n",
            "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 71\n",
            "[LightGBM] [Info] Start training from score 9627962.017750\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000947 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1952\n",
            "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 73\n",
            "[LightGBM] [Info] Start training from score 9556175.422500\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001418 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1952\n",
            "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 73\n",
            "[LightGBM] [Info] Start training from score 9602417.782250\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000704 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1949\n",
            "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 73\n",
            "[LightGBM] [Info] Start training from score 9603492.210500\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000645 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1942\n",
            "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 71\n",
            "[LightGBM] [Info] Start training from score 9612858.139000\n",
            "  Mean CV MAPE: 0.1603\n",
            "  Std CV MAPE: 0.0031\n",
            "\n",
            "--- All Model Results ---\n",
            "RandomForestRegressor: Mean MAPE = 0.1680, Std MAPE = 0.0038\n",
            "GradientBoostingRegressor: Mean MAPE = 0.1743, Std MAPE = 0.0036\n",
            "LinearRegression: Mean MAPE = 0.2006, Std MAPE = 0.0049\n",
            "XGBRegressor: Mean MAPE = 0.1640, Std MAPE = 0.0045\n",
            "LGBMRegressor: Mean MAPE = 0.1603, Std MAPE = 0.0031\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "\n",
        "for name, model in models:\n",
        "    print(f\"\\nEvaluating {name}...\")\n",
        "\n",
        "    # Create the full pipeline for the current model\n",
        "    current_pipeline = make_full_pipeline(model, borough_to_praha, unique_words)\n",
        "\n",
        "    # Perform cross-validation with MAPE, suppressing FutureWarnings and UserWarnings\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter(\"ignore\", FutureWarning)\n",
        "        warnings.simplefilter(\"ignore\", UserWarning)\n",
        "        cv_scores_mape = cross_val_score(current_pipeline, X, y, cv=kf, scoring=mape, error_score='raise')\n",
        "    cv_mape = -cv_scores_mape # Multiply by -1 because make_scorer returns negative scores for metrics where lower is better\n",
        "\n",
        "    mean_mape = np.mean(cv_mape)\n",
        "    std_mape = np.std(cv_mape)\n",
        "\n",
        "    results[name] = {\"mean_mape\": mean_mape, \"std_mape\": std_mape}\n",
        "\n",
        "    print(f\"  Mean CV MAPE: {mean_mape:.4f}\")\n",
        "    print(f\"  Std CV MAPE: {std_mape:.4f}\")\n",
        "\n",
        "print(\"\\n--- All Model Results ---\")\n",
        "for name, metrics in results.items():\n",
        "    print(f\"{name}: Mean MAPE = {metrics['mean_mape']:.4f}, Std MAPE = {metrics['std_mape']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebe50245"
      },
      "source": [
        "## Compare Model Performance\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3fed073",
        "outputId": "7c9523ce-1df9-4dc8-af6c-2a14c00bcd10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Comparative Model Performance (Sorted by Mean MAPE) ---\n",
            "                       Model  Mean MAPE  Std MAPE\n",
            "4              LGBMRegressor   0.160347  0.003092\n",
            "3               XGBRegressor   0.163993  0.004540\n",
            "0      RandomForestRegressor   0.167998  0.003772\n",
            "1  GradientBoostingRegressor   0.174311  0.003552\n",
            "2           LinearRegression   0.200640  0.004851\n"
          ]
        }
      ],
      "source": [
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "results_df.index.name = 'Model'\n",
        "results_df = results_df.reset_index()\n",
        "results_df.columns = ['Model', 'Mean MAPE', 'Std MAPE']\n",
        "\n",
        "# Sort by Mean MAPE in ascending order\n",
        "results_df = results_df.sort_values(by='Mean MAPE')\n",
        "\n",
        "print(\"\\n--- Comparative Model Performance (Sorted by Mean MAPE) ---\")\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e509bc6",
        "outputId": "0aac5703-4a45-4c88-c5ab-8a748ca09b52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imported RandomizedSearchCV and scipy.stats distributions.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "print(\"Imported RandomizedSearchCV and scipy.stats distributions.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8d8bfc9",
        "outputId": "a04e9350-5fcf-419f-c90c-734cc34ba4f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "205 fits failed out of a total of 250.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "115 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py\", line 662, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/sklearn.py\", line 1398, in fit\n",
            "    super().fit(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/sklearn.py\", line 1049, in fit\n",
            "    self._Booster = train(\n",
            "                    ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/engine.py\", line 297, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 3656, in __init__\n",
            "    train_set.construct()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 2590, in construct\n",
            "    self._lazy_init(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 2183, in _lazy_init\n",
            "    self.__init_from_csr(data, params_str, ref_dataset)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 2403, in __init_from_csr\n",
            "    _safe_call(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
            "lightgbm.basic.LightGBMError: Check failed: (bagging_fraction) <= (1.0) at /__w/1/s/lightgbm-python/src/io/config_auto.cpp, line 367 .\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "90 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py\", line 662, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/sklearn.py\", line 1398, in fit\n",
            "    super().fit(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/sklearn.py\", line 1049, in fit\n",
            "    self._Booster = train(\n",
            "                    ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/engine.py\", line 297, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 3656, in __init__\n",
            "    train_set.construct()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 2590, in construct\n",
            "    self._lazy_init(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 2183, in _lazy_init\n",
            "    self.__init_from_csr(data, params_str, ref_dataset)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 2403, in __init_from_csr\n",
            "    _safe_call(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
            "lightgbm.basic.LightGBMError: Check failed: (feature_fraction) <= (1.0) at /__w/1/s/lightgbm-python/src/io/config_auto.cpp, line 385 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best parameters found: {'model__colsample_bytree': np.float64(0.8395618906669724), 'model__learning_rate': np.float64(0.05346846162736693), 'model__max_depth': 14, 'model__min_child_samples': 25, 'model__n_estimators': 515, 'model__num_leaves': 23, 'model__reg_alpha': np.float64(0.040426663166357624), 'model__reg_lambda': np.float64(0.18482722803070223), 'model__subsample': np.float64(0.8421599382774259)}\n",
            "Best MAPE score (negative is better before multiplying by -1): 0.1593651923023014\n",
            "Tuned LGBM model stored.\n"
          ]
        }
      ],
      "source": [
        "lgbm_base = LGBMRegressor(random_state=42, verbose=-1) # verbose=-1 to suppress LightGBM warnings during search\n",
        "\n",
        "# Create the full pipeline for the base LGBM model\n",
        "pipeline_lgbm = make_full_pipeline(lgbm_base, borough_to_praha, unique_words)\n",
        "\n",
        "# Define the parameter distribution for LGBMRegressor\n",
        "param_dist_lgbm = {\n",
        "    'model__n_estimators': randint(100, 1000),\n",
        "    'model__learning_rate': uniform(0.01, 0.3),\n",
        "    'model__num_leaves': randint(20, 60),\n",
        "    'model__max_depth': randint(5, 15),\n",
        "    'model__reg_alpha': uniform(0, 0.5),\n",
        "    'model__reg_lambda': uniform(0, 0.5),\n",
        "    'model__min_child_samples': randint(20, 50),\n",
        "    'model__subsample': uniform(0.6, 1.0),\n",
        "    'model__colsample_bytree': uniform(0.6, 1.0),\n",
        "}\n",
        "\n",
        "# Instantiate RandomizedSearchCV\n",
        "lgbm_random_search = RandomizedSearchCV(\n",
        "    estimator=pipeline_lgbm,\n",
        "    param_distributions=param_dist_lgbm,\n",
        "    n_iter=50, # Number of parameter settings that are sampled\n",
        "    cv=kf,\n",
        "    scoring=mape,\n",
        "    random_state=42,\n",
        "    verbose=1,\n",
        "    n_jobs=-1 # Use all available cores\n",
        ")\n",
        "\n",
        "# Fit RandomizedSearchCV to the training data\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", FutureWarning)\n",
        "    warnings.simplefilter(\"ignore\", UserWarning)\n",
        "    lgbm_random_search.fit(X, y)\n",
        "\n",
        "# Print the best parameters and best score\n",
        "print(\"\\nBest parameters found:\", lgbm_random_search.best_params_)\n",
        "print(\"Best MAPE score (negative is better before multiplying by -1):\", -lgbm_random_search.best_score_)\n",
        "\n",
        "# Store the best estimator\n",
        "tuned_lgbm_model = lgbm_random_search.best_estimator_\n",
        "print(\"Tuned LGBM model stored.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "52f354ae",
        "outputId": "6985ffec-efdf-48fc-eff6-6037f2f0c7f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "\n",
            "Best parameters found: {'model__colsample_bytree': np.float64(0.695824756266789), 'model__learning_rate': np.float64(0.05346846162736693), 'model__max_depth': 14, 'model__min_child_samples': 25, 'model__n_estimators': 515, 'model__num_leaves': 23, 'model__reg_alpha': np.float64(0.040426663166357624), 'model__reg_lambda': np.float64(0.18482722803070223), 'model__subsample': np.float64(0.6968639753109703)}\n",
            "Best MAPE score (negative is better before multiplying by -1): 0.15919373182184965\n",
            "Tuned LGBM model stored.\n"
          ]
        }
      ],
      "source": [
        "lgbm_base = LGBMRegressor(random_state=42, verbose=-1) # verbose=-1 to suppress LightGBM warnings during search\n",
        "\n",
        "# Create the full pipeline for the base LGBM model\n",
        "pipeline_lgbm = make_full_pipeline(lgbm_base, borough_to_praha, unique_words)\n",
        "\n",
        "# Define the parameter distribution for LGBMRegressor\n",
        "param_dist_lgbm = {\n",
        "    'model__n_estimators': randint(100, 1000),\n",
        "    'model__learning_rate': uniform(0.01, 0.3),\n",
        "    'model__num_leaves': randint(20, 60),\n",
        "    'model__max_depth': randint(5, 15),\n",
        "    'model__reg_alpha': uniform(0, 0.5),\n",
        "    'model__reg_lambda': uniform(0, 0.5),\n",
        "    'model__min_child_samples': randint(20, 50),\n",
        "    'model__subsample': uniform(0.6, 0.4), # Corrected range: values from 0.6 to 0.6 + 0.4 = 1.0\n",
        "    'model__colsample_bytree': uniform(0.6, 0.4), # Corrected range: values from 0.6 to 0.6 + 0.4 = 1.0\n",
        "}\n",
        "\n",
        "# Instantiate RandomizedSearchCV\n",
        "lgbm_random_search = RandomizedSearchCV(\n",
        "    estimator=pipeline_lgbm,\n",
        "    param_distributions=param_dist_lgbm,\n",
        "    n_iter=50, # Number of parameter settings that are sampled\n",
        "    cv=kf,\n",
        "    scoring=mape,\n",
        "    random_state=42,\n",
        "    verbose=1,\n",
        "    n_jobs=-1 # Use all available cores\n",
        ")\n",
        "\n",
        "# Fit RandomizedSearchCV to the training data\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", FutureWarning)\n",
        "    warnings.simplefilter(\"ignore\", UserWarning)\n",
        "    lgbm_random_search.fit(X, y)\n",
        "\n",
        "# Print the best parameters and best score\n",
        "print(\"\\nBest parameters found:\", lgbm_random_search.best_params_)\n",
        "print(\"Best MAPE score (negative is better before multiplying by -1):\", -lgbm_random_search.best_score_)\n",
        "\n",
        "# Store the best estimator\n",
        "tuned_lgbm_model = lgbm_random_search.best_estimator_\n",
        "print(\"Tuned LGBM model stored.\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39fc369c",
        "outputId": "0237f47b-89d9-4c02-87cb-1128dde3a2fe"
      },
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "# Instantiate MLPRegressor\n",
        "# Using some reasonable default parameters for a first pass\n",
        "# random_state is important for reproducibility\n",
        "mlp_base = MLPRegressor(random_state=42, max_iter=500, learning_rate_init=0.001)\n",
        "\n",
        "# Create the full pipeline for the MLPRegressor\n",
        "pipeline_mlp = make_full_pipeline(mlp_base, borough_to_praha, unique_words)\n",
        "\n",
        "print(\"\\nEvaluating MLPRegressor...\")\n",
        "\n",
        "# Perform cross-validation with MAPE, suppressing warnings\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", FutureWarning)\n",
        "    warnings.simplefilter(\"ignore\", UserWarning)\n",
        "    cv_scores_mape_mlp = cross_val_score(pipeline_mlp, X, y, cv=kf, scoring=mape, error_score='raise')\n",
        "cv_mape_mlp = -cv_scores_mape_mlp # Multiply by -1 for positive MAPE\n",
        "\n",
        "mean_mape_mlp = np.mean(cv_mape_mlp)\n",
        "std_mape_mlp = np.std(cv_mape_mlp)\n",
        "\n",
        "# Store the results\n",
        "results[\"MLPRegressor\"] = {\"mean_mape\": mean_mape_mlp, \"std_mape\": std_mape_mlp}\n",
        "\n",
        "print(f\"  Mean CV MAPE for MLPRegressor: {mean_mape_mlp:.4f}\")\n",
        "print(f\"  Std CV MAPE for MLPRegressor: {std_mape_mlp:.4f}\")\n",
        "\n",
        "# Add the tuned LGBM model to results for comparison\n",
        "# Note: tuned_lgbm_model is a pipeline, so we need to extract its model's performance\n",
        "# The best_score_ from RandomizedSearchCV already gives the CV performance for the tuned model.\n",
        "results[\"LGBMRegressor (Tuned)\"] = {\"mean_mape\": -lgbm_random_search.best_score_, \"std_mape\": np.nan} # Std dev not directly available from best_score_ but can be computed from cv_results_ if needed.\n",
        "\n",
        "print(\"\\n--- Updated All Model Results ---\")\n",
        "for name, metrics in results.items():\n",
        "    print(f\"{name}: Mean MAPE = {metrics['mean_mape']:.4f}, Std MAPE = {metrics['std_mape']:.4f}\")"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating MLPRegressor...\n",
            "  Mean CV MAPE for MLPRegressor: 0.7292\n",
            "  Std CV MAPE for MLPRegressor: 0.0115\n",
            "\n",
            "--- Updated All Model Results ---\n",
            "RandomForestRegressor: Mean MAPE = 0.1680, Std MAPE = 0.0038\n",
            "GradientBoostingRegressor: Mean MAPE = 0.1743, Std MAPE = 0.0036\n",
            "LinearRegression: Mean MAPE = 0.2006, Std MAPE = 0.0049\n",
            "XGBRegressor: Mean MAPE = 0.1640, Std MAPE = 0.0045\n",
            "LGBMRegressor: Mean MAPE = 0.1603, Std MAPE = 0.0031\n",
            "MLPRegressor: Mean MAPE = 0.7292, Std MAPE = 0.0115\n",
            "LGBMRegressor (Tuned): Mean MAPE = 0.1592, Std MAPE = nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "273eaf40",
        "outputId": "35350600-9d2d-429b-e5d3-d9ea232971e7"
      },
      "source": [
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "results_df.index.name = 'Model'\n",
        "results_df = results_df.reset_index()\n",
        "results_df.columns = ['Model', 'Mean MAPE', 'Std MAPE']\n",
        "\n",
        "# Sort by Mean MAPE in ascending order\n",
        "results_df = results_df.sort_values(by='Mean MAPE')\n",
        "\n",
        "print(\"\\n--- Comparative Model Performance (Sorted by Mean MAPE) ---\")\n",
        "print(results_df)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Comparative Model Performance (Sorted by Mean MAPE) ---\n",
            "                       Model  Mean MAPE  Std MAPE\n",
            "6      LGBMRegressor (Tuned)   0.159194       NaN\n",
            "4              LGBMRegressor   0.160347  0.003092\n",
            "3               XGBRegressor   0.163993  0.004540\n",
            "0      RandomForestRegressor   0.167998  0.003772\n",
            "1  GradientBoostingRegressor   0.174311  0.003552\n",
            "2           LinearRegression   0.200640  0.004851\n",
            "5               MLPRegressor   0.729189  0.011485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction for test data\n"
      ],
      "metadata": {
        "id": "_aRqmvx4LI9j"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "11b16dbe",
        "outputId": "9721b326-0162-4fd0-9e43-7970f96fe6a1"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Make predictions on the test set using the final tuned LGBM model\n",
        "final_predictions = tuned_lgbm_model.predict(test)\n",
        "\n",
        "# Create a DataFrame for the predictions\n",
        "predictions_df = pd.DataFrame({\n",
        "    'id': test['id'],\n",
        "    'predicted_price': final_predictions\n",
        "})\n",
        "\n",
        "# Display the predictions\n",
        "display(predictions_df.head())"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     id  predicted_price\n",
              "0  8795     6.192617e+06\n",
              "1  6516     1.008295e+07\n",
              "2  4714     6.542120e+06\n",
              "3  8423     9.816702e+06\n",
              "4  5361     9.530782e+06"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eeb74af6-1e76-4b3d-8f2a-6f39c086860b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>predicted_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8795</td>\n",
              "      <td>6.192617e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6516</td>\n",
              "      <td>1.008295e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4714</td>\n",
              "      <td>6.542120e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8423</td>\n",
              "      <td>9.816702e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5361</td>\n",
              "      <td>9.530782e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eeb74af6-1e76-4b3d-8f2a-6f39c086860b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eeb74af6-1e76-4b3d-8f2a-6f39c086860b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eeb74af6-1e76-4b3d-8f2a-6f39c086860b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b0e2820c-c137-4994-b9be-5055607a4402\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b0e2820c-c137-4994-b9be-5055607a4402')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b0e2820c-c137-4994-b9be-5055607a4402 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(predictions_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1810,\n        \"min\": 4714,\n        \"max\": 8795,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          6516,\n          5361,\n          4714\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1899790.8685132521,\n        \"min\": 6192616.954113568,\n        \"max\": 10082946.065651309,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          10082946.065651309,\n          9530782.128571019,\n          6542119.966397249\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTOnvjobdBdMdTPCCHsZoS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}