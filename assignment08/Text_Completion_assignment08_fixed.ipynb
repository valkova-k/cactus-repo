{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9YMjwQWkoxK"
      },
      "source": [
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + \u2b50 <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> \u2b50\n",
        "</div>\n",
        "\n",
        "To install Unsloth your local device, follow [our guide](https://docs.unsloth.ai/get-started/install-and-update). This notebook is licensed [LGPL-3.0](https://github.com/unslothai/notebooks?tab=LGPL-3.0-1-ov-file#readme).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBb_c54ekoxM"
      },
      "source": [
        "### News"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFnKaeYkkoxN"
      },
      "source": [
        "\n",
        "Unsloth's [Docker image](https://hub.docker.com/r/unsloth/unsloth) is here! Start training with no setup & environment issues. [Read our Guide](https://docs.unsloth.ai/new/how-to-train-llms-with-unsloth-and-docker).\n",
        "\n",
        "[gpt-oss RL](https://docs.unsloth.ai/new/gpt-oss-reinforcement-learning) is now supported with the fastest inference & lowest VRAM. Try our [new notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/gpt-oss-(20B)-GRPO.ipynb) which creates kernels!\n",
        "\n",
        "Introducing [Vision](https://docs.unsloth.ai/new/vision-reinforcement-learning-vlm-rl) and [Standby](https://docs.unsloth.ai/basics/memory-efficient-rl) for RL! Train Qwen, Gemma etc. VLMs with GSPO - even faster with less VRAM.\n",
        "\n",
        "Unsloth now supports Text-to-Speech (TTS) models. Read our [guide here](https://docs.unsloth.ai/basics/text-to-speech-tts-fine-tuning).\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8aqbsNUkoxO"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jBJudOBxkoxO",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762698535931,
          "user_tz": -60,
          "elapsed": 34616,
          "user": {
            "displayName": "Kate\u0159ina V\u00e1lkov\u00e1",
            "userId": "13944778042770891539"
          }
        }
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os, re\n",
        "\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    import torch\n",
        "    v = re.match(r\"[0-9\\.]{3,}\", str(torch.__version__)).group(0)\n",
        "    xformers = \"xformers==\" + (\"0.0.32.post2\" if v == \"2.8.0\" else \"0.0.29.post3\")\n",
        "\n",
        "    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
        "    !pip install --no-deps unsloth\n",
        "    !pip install transformers==4.56.2  # nov\u011bj\u0161\u00ed kompatibiln\u00ed verze"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Alb100jjkoxP"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "2bEVllhvq10D",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762698535960,
          "user_tz": -60,
          "elapsed": 2,
          "user": {
            "displayName": "Kate\u0159ina V\u00e1lkov\u00e1",
            "userId": "13944778042770891539"
          }
        }
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCJwW0ugkoxP"
      },
      "source": [
        "#### Text Completion / Raw Text Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdPaYbLQkoxP",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762698535966,
          "user_tz": -60,
          "elapsed": 4,
          "user": {
            "displayName": "Kate\u0159ina V\u00e1lkov\u00e1",
            "userId": "13944778042770891539"
          }
        },
        "outputId": "cb1423c9-604e-4e76-e360-e3cb9bf2b3bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: UNSLOTH_RETURN_LOGITS=1 # Run this to disable CCE since it is not supported for CPT\n"
          ]
        }
      ],
      "source": [
        "%env UNSLOTH_RETURN_LOGITS=1 # Run this to disable CCE since it is not supported for CPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380,
          "referenced_widgets": [
            "823810993bef4d71b4f9d3e371fa1912",
            "2128294c3d224ce2a893b1b71c6de37e",
            "4466f776913f4db3b6534bc051fb98cf",
            "3ab8c7e36b9c453ba5733c3929d999e9",
            "8cbefcda5d97467da58bec6f1ed48a4a",
            "5a7dde72b58249c5879daaca74de2666",
            "3b4d944aa0c44dc68435f32287f32749",
            "c6e5876fced8454db5face9a5098e97f",
            "c04bc10c568a4d45bc4bbc696c3656b8",
            "8c3a38b831414f0fb3d0254cb1e53c75",
            "a65368c597384f0195997eef83e4d28f",
            "4a7fc02ecc6c4c89b9c4be3dc9fe4811",
            "82751e2493f94695bc24b65f9c09ae5d",
            "a3a63b33edc54c449850d1391f89210c",
            "418ab54edcec42d280f288b8b0815ce4",
            "212b5e306e344161999b7b1bb2db3a91",
            "6f4832dc40cf4a42a15fe3ea4b09c6ba",
            "47087cc956484f6382696f3907aa70a5",
            "73ac306ac7fa4f08b1cb68c70b1f91e9",
            "8dca7ff2ef1d435bb8194c47de5c1a0b",
            "dfd2ef71d1574f2e8517f041294e0a03",
            "b892ebbda1d44ac58cba2fe81026914c",
            "1ce49fabd3984a5495597459fcdd7f7b",
            "4cad0f5a98d44f87a31e4376555c0612",
            "0f8c2c00338f4fe79ff7417839388dc1",
            "e48510d45d024d989e96c7899662d9d8",
            "987581aa2259471782d160ffbe43360b",
            "1fd5ee739fb845959dba5d9890db9725",
            "5386340b91a941c8aa749ba0738b0258",
            "59a7a49d7d0b46a498d238c26d08e8f5",
            "e5f516f3e9fc430bb2c6197221145549",
            "7328b904c9a84720954b9aabf892578f",
            "ca19b5b2a53043feb52a32a3b9f11276",
            "b4b8ad12d2ac45468ed5489c8a77a1ca",
            "1bd62253587b4cd58b30eec18a3f23d5",
            "17020db5b012454d8dd7579c60738e2b",
            "de510d8c3a9a45f49f8cf8368ebdb88d",
            "e01bfa9cf57942aaad78aaf809ae49c6",
            "b55f920ca02749a898f3e81205255f79",
            "30aa58034de34f2ca1c6e60861742eed",
            "591d451d8e444f48b5ae40020f6d61c8",
            "eb9fdef9be7f4d868826e64775b2c753",
            "7504a88f21f043aa9bd31f6c29f0ee4f",
            "8ba684a7d76a4dd5a6d18c3d8fd7ae3b",
            "9d6c6a72ce244da0a4e9687185df7cfb",
            "8b74d1c9e89042fca5808838357f36f8",
            "55ea8439abfc47e29bb8be54df19c14e",
            "b4053bc46804448ca756a4041e981690",
            "500f42d7ce3940debc227d945a099ca7",
            "fa5440b5e545401d8869108999eb2e16",
            "f57fa96af4144eaa8bbe1c3933851a8a",
            "0704612d5ee14dff8c4c1a511e1f1799",
            "8a38cc3c3fa34b949708e0e911c9b292",
            "f3f63cd0e8644af19f00e86f84c13976",
            "cd5e41ada10344e28e5b9693a5e1f7da",
            "33b11f8a1a454a2d9662b51331ba8333",
            "8d9e0b9afde34f9da922abcd5b440094",
            "e827088bbcd84149bed34f791c468e5d",
            "3bea9f1c2c754794ac9706d9e4f26f1e",
            "1601b00407934689a31ba1f85a15060b",
            "cb24e89b473d44958f87091de5afb43e",
            "c668f7505fd4463ca56250a717d29b67",
            "c7cd423328bd45db8d2eee3deff128ce",
            "2f0145e744914d2eabac92ef879bd984",
            "ab672f287fe24d66b06199ea9a594368",
            "a48c9aaa26e24e809df9ef6afdd10826",
            "84f5d44897504b98ba5137e69055fde5",
            "f73b92eedb994a6bad9297f5e7381274",
            "dd9b0abd70054cb59f6549456c0d61d1",
            "b08e30b274bb4c1c96a4901efceb714c",
            "f2f9c635135e48daa5a1d9cc27c120cd",
            "4b225501d36044ee88bfe5102db47bac",
            "aa99f050c98f4b3488b6dd1eec2f4e29",
            "a2d85993363f4cefbfc5d46a39ac104e",
            "22029bade99c44e1a5dc87e298ac71bf",
            "71baee810313498cb114d1c2e9858324",
            "02f3a253d69c48b3bce9692c316f0e5c"
          ]
        },
        "id": "QmUBVEnvCDJv",
        "outputId": "6c5b2b41-13a3-4286-e46b-42846e6e7387",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762698655967,
          "user_tz": -60,
          "elapsed": 119998,
          "user": {
            "displayName": "Kate\u0159ina V\u00e1lkov\u00e1",
            "userId": "13944778042770891539"
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ud83e\udda5 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "\ud83e\udda5 Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.11.2: Fast Mistral patching. Transformers: 4.56.2.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.26G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "823810993bef4d71b4f9d3e371fa1912"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/194 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a7fc02ecc6c4c89b9c4be3dc9fe4811"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ce49fabd3984a5495597459fcdd7f7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4b8ad12d2ac45468ed5489c8a77a1ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d6c6a72ce244da0a4e9687185df7cfb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/458 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33b11f8a1a454a2d9662b51331ba8333"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84f5d44897504b98ba5137e69055fde5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 4096 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",      # New Mistral v3 2x faster!\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "    \"unsloth/llama-3-8b-bnb-4bit\",           # Llama-3 15 trillion tokens model 2x faster!\n",
        "    \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
        "    \"unsloth/llama-3-70b-bnb-4bit\",\n",
        "    \"unsloth/Phi-3-mini-4k-instruct\",        # Phi-3 2x faster!\n",
        "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "    \"unsloth/mistral-7b-bnb-4bit\",\n",
        "    \"unsloth/gemma-7b-bnb-4bit\",             # Gemma 2.2x faster!\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Phi-3-mini-4k-instruct\", # \"unsloth/mistral-7b\" for 16bit loading\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd9bTZd1aaL"
      },
      "source": [
        "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!\n",
        "\n",
        "We also add `embed_tokens` and `lm_head` to allow the model to learn out of distribution data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bZsfBuZDeCL",
        "outputId": "48081297-0dac-44d0-d174-e85b089ee067",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762698675559,
          "user_tz": -60,
          "elapsed": 19590,
          "user": {
            "displayName": "Kate\u0159ina V\u00e1lkov\u00e1",
            "userId": "13944778042770891539"
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Offloading input_embeddings to disk to save VRAM\n",
            "Unsloth: Offloading output_embeddings to disk to save VRAM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.11.2 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Training embed_tokens in mixed precision to save VRAM\n",
            "Unsloth: Training lm_head in mixed precision to save VRAM\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 128, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "\n",
        "                      \"embed_tokens\", \"lm_head\",], # Add for continual pretraining\n",
        "    lora_alpha = 32,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = True,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vITh0KVJ10qX"
      },
      "source": [
        "<a name=\"Data\"></a>\n",
        "### Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Downloading dataset\n",
        "!wget -nc https://raw.githubusercontent.com/valkova-k/cactus-repo/refs/heads/main/assignment05/combined_books.txt\n",
        "\n",
        "pattern = r'(\\.\\s*\\.\\s*\\.\\s*\\d+)|([\u2013-]\\s*\\d+\\s*[\u2013-])'\n",
        "\n",
        "with open(\"combined_books.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = \"\".join(line for line in f if not re.search(pattern, line))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TReBGSsKlVvY",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762698676217,
          "user_tz": -60,
          "elapsed": 655,
          "user": {
            "displayName": "Kate\u0159ina V\u00e1lkov\u00e1",
            "userId": "13944778042770891539"
          }
        },
        "outputId": "0a53df65-c18c-442d-a910-fba191e300a7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-09 14:31:14--  https://raw.githubusercontent.com/valkova-k/cactus-repo/refs/heads/main/assignment05/combined_books.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2588154 (2.5M) [text/plain]\n",
            "Saving to: \u2018combined_books.txt\u2019\n",
            "\n",
            "combined_books.txt  100%[===================>]   2.47M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-11-09 14:31:14 (52.7 MB/s) - \u2018combined_books.txt\u2019 saved [2588154/2588154]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"length of dataset in characters: \", len(raw_text))\n",
        "print(raw_text[:5000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPeDDMwZmIWq",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762698676245,
          "user_tz": -60,
          "elapsed": 26,
          "user": {
            "displayName": "Kate\u0159ina V\u00e1lkov\u00e1",
            "userId": "13944778042770891539"
          }
        },
        "outputId": "41f5c1af-4fb0-4776-ad57-5e7b5b49c4e2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters:  2304298\n",
            "Produced by Miloslav Izar RUSK\u00c1 KNIHOVNA IX. SPISY FEDORA MICHAJLOVI\u010cE DOSTOJEVSK\u00c9HO. P\u0159eklad rediguje JAROM\u00cdR HRUB\u00dd Svazek I. Z\u00c1PISKY Z MRTV\u00c9HO DOMU. P\u0159elo\u017eil H. JARO\u0160. V PRAZE 1891. Tiskem a n\u00e1kladem J. Otty. \u010c\u00c1ST PRV\u00c1. \u00daVOD. V dalek\u00fdch kraj\u00edch Sibi\u0159e, uprost\u0159ed step\u00ed, hor a neproniknuteln\u00fdch les\u016f vyskytuj\u00ed se z\u0159\u00eddka malink\u00e1 m\u011bsta s jedn\u00edm nebo nanejv\u00fd\u0161 se dv\u011bma tis\u00edci obyvatel\u016f, d\u0159ev\u011bn\u00e1 to, ne\u00fahledn\u00e1 m\u011bsta se dv\u011bma chr\u00e1my, jedn\u00edm ve m\u011bst\u011b, druh\u00fdm na h\u0159bitov\u011b, a podobn\u00e1 v\u00edce k slu\u0161n\u00e9 vesnici pod Moskvou ne\u017e k m\u011bstu. B\u00fdvaj\u00ed oby\u010dejn\u011b hojn\u011b opat\u0159ena policejn\u00edmi hejtmany, komisary a ostatn\u00edmi pod\u0159\u00edzen\u00fdmi policejn\u00edmi dozorci. V Sibi\u0159i v\u016fbec p\u0159es to, \u017ee je tam zima. jsou \u00fa\u0159ady neoby\u010dejn\u011b teplou\u010dk\u00e9. Lid tamn\u00ed je prost\u00fd, nena\u010dichl\u00fd liber\u00e1lnost\u00ed; po\u0159\u00e1dky star\u00e9, pevn\u00e9, stalet\u00edmi posv\u011bcen\u00e9. \u00da\u0159edn\u00edky, kte\u0159\u00ed pr\u00e1vem hraj\u00ed \u00falohu sibi\u0159sk\u00e9 \u0161lechty, jsou bu\u010f tuzemci, zako\u0159en\u011bl\u00ed Sibi\u0159\u00e1ci, anebo rod\u00e1ci z evropsk\u00e9ho Ruska, zejm\u00e9na hlavn\u00edch m\u011bst, kte\u0159\u00ed se dali p\u0159iv\u00e1biti p\u0159\u00eddavkem k slu\u017en\u00e9mu, dvojn\u00e1sobnou n\u00e1hradou cestovn\u00e9ho a sv\u016fdn\u00fdmi nad\u011bjemi do budoucna. Ti z nich, kte\u0159\u00ed um\u011bj\u00ed \u0159e\u0161iti h\u00e1danku \u017eivota, z\u016fst\u00e1vaj\u00ed skoro v\u0161ichni v Sibi\u0159i, r\u00e1di se v n\u00ed usazuj\u00ed a zapou\u0161t\u011bj\u00ed pevn\u011b ko\u0159eny. Za to pozd\u011bji nesou bohat\u00e9 a sladk\u00e9 ovoce. Jin\u00e9 v\u0161ak, lidi to lehkomysln\u00e9, kte\u0159\u00ed neum\u011bj\u00ed \u0159e\u0161iti h\u00e1danku \u017eivota, Sibi\u0159 brzy omrz\u00ed a p\u0159ed nimi vznik\u00e1 teskliv\u00e1 ot\u00e1zka: Pro\u010d jen sem p\u0159ijeli? Nemohou se do\u010dkati, kdy vypr\u0161\u00ed z\u00e1konit\u00e1 lh\u016fta \u00fa\u0159edn\u00edho pobytu v Sibi\u0159i, toti\u017e t\u0159i l\u00e9ta, a jakmile uplynula, ihned se nam\u00e1haj\u00ed, aby byli p\u0159evedeni na jin\u00e9 m\u00edsto, vracej\u00ed se do sv\u00e9 ot\u010diny, sp\u00edlaj\u00ed Sibi\u0159i a trop\u00ed si z n\u00ed \u017eerty. Av\u0161ak nepr\u00e1vem: v Sibi\u0159i m\u016f\u017ee b\u00fdti \u010dlov\u011bk bla\u017een\u011b \u017eiv nejen jako \u00fa\u0159edn\u00edk, n\u00fdbr\u017e i vzhledem k mnoh\u00fdm jin\u00fdm okolnostem. Podneb\u00ed jest v\u00fdte\u010dn\u00e9; je tam mnoho neoby\u010dejn\u011b bohat\u00fdch a pohostinn\u00fdch obchodn\u00edk\u016f; mnoho nev\u0161edn\u011b z\u00e1mo\u017en\u00fdch jinorodc\u016f. D\u00edvky kvetou r\u016f\u017eemi a jsou svrchovan\u011b mravny. Pernat\u00e1 zv\u011b\u0159 l\u00edt\u00e1 po ulic\u00edch a sama p\u0159iletuje k lovci. \u0160ampa\u0148sk\u00e9ho vypije se tak mnoho, \u017ee neuv\u011b\u0159\u00edte. Kavi\u00e1r je ku podivu. \u00daroda v n\u011bkter\u00fdch m\u00edstnostech p\u0159in\u00e1\u0161\u00ed patn\u00e1ct zrn z jednoho... V\u016fbec zem\u011b po\u017eehnan\u00e1. Jest pouze zapot\u0159eb\u00ed, aby j\u00ed \u010dlov\u011bk um\u011bl u\u017eiti. A v Sibi\u0159i j\u00ed u\u017e\u00edvati um\u011bj\u00ed. V jednom z takov\u00fdch vesel\u00fdch, sebou spokojen\u00fdch m\u011bste\u010dek s roztomil\u00fdm obyvatelstvem, jeho\u017e pam\u00e1tka nevymiz\u00ed z m\u00e9ho srdce, setkal jsem se s Alexandrem Petrovi\u010dem Gorjan\u010dikovem, tamn\u00edm osadn\u00edkem, rodil\u00fdm \u0161lechticem a statk\u00e1\u0159em z evropsk\u00e9ho Ruska, odkud\u017e pro vra\u017edu sv\u00e9 \u017eeny byl odesl\u00e1n na Sibi\u0159, kde konal nucen\u00e9 pr\u00e1ce jako trestanec druh\u00e9 t\u0159\u00eddy, a kdy\u017e uplynula z\u00e1konem mu vym\u011b\u0159en\u00e1 desetilet\u00e1 lh\u016fta trestu, stal se osadn\u00edkem ve m\u011bste\u010dku K., kde\u017e pokorn\u011b a ti\u0161e tr\u00e1vil ostatek sv\u00e9ho \u017eivota. Domovsk\u00e9 pr\u00e1vo m\u011bl vlastn\u011b v jedn\u00e9 volosti*), soused\u00edc\u00ed s m\u011bstem, ale bydlel ve m\u011bst\u011b, kde se mu naskytovala mo\u017enost, opat\u0159iti si t\u0159ebas jen skrovnou v\u00fd\u017eivu vyu\u010dov\u00e1n\u00edm d\u011bt\u00ed. V sibi\u0159sk\u00fdch m\u011bstech \u010dasto se setk\u00e1te s u\u010diteli, b\u00fdval\u00fdmi trestanci; jimi nepovrhuj\u00ed. Vyu\u010duj\u00ed hlavn\u011b francouzsk\u00e9mu jazyku, bez n\u011bho\u017e se \u010dlov\u011bk neobejde v b\u011bhu \u017eivota, o n\u011bm\u017e by v\u0161ak bez nich ve vzd\u00e1len\u00fdch kraj\u00edch Sibi\u0159e nem\u011bli ani pon\u011bt\u00ed. Poprv\u00e9 jsem se setkal s Alexandrem Petrovi\u010dem v dom\u011b jist\u00e9ho star\u00e9ho, zaslou\u017eil\u00e9ho a pohostinn\u00e9ho \u00fa\u0159edn\u00edka Ivana Ivanovi\u010de Gvozdikova, jen\u017e m\u011bl p\u011bt velice nad\u011bjn\u00fdch dcer r\u016fzn\u00e9ho st\u00e1\u0159\u00ed. Alexandr Petrovi\u010d jim d\u00e1val hodiny \u010dty\u0159ikr\u00e1t za t\u00fdden, po t\u0159iceti kopejk\u00e1ch st\u0159\u00edbra za hodinu. Jeho zevn\u011bj\u0161ek obr\u00e1til k sob\u011b mou pozornost. Byl to neoby\u010dejn\u011b bled\u00fd, huben\u00fd \u010dlov\u011bk, je\u0161t\u011b ne star\u00fd, asi t\u0159icetip\u011btilet\u00fd, malink\u00fd a slabou\u010dk\u00fd. Oble\u010den b\u00fdval v\u017edycky velmi \u010dist\u011b po evropsku. Dali-li jste se s n\u00edm do \u0159e\u010di, hled\u011bl na v\u00e1s ne- *) Volost\u00ed slov\u011b venkovsk\u00fd, do jist\u00e9 m\u00edry samospr\u00e1vn\u00fd okrsek, s volen\u00fdm starostou a vlastn\u00edm, volen\u00fdm soudem, pod jeho\u017e pravomoc spadaj\u00ed v\u0161ak jen \u010dlenov\u00e9 selsk\u00fdch obc\u00ed. oby\u010dejn\u011b up\u0159en\u011b a pozorn\u011b, s p\u0159\u00edsnou zdvo\u0159ilost\u00ed vyslechl ka\u017ed\u00e9 va\u0161e slovo, jako by se sna\u017eil, vmysliti se v jeho smysl, jako byste mu svou ot\u00e1zkou byli dali h\u00e1danku, anebo se chcete dop\u00e1trati n\u011bkter\u00e9ho jeho tajemstv\u00ed; pak teprv odpov\u00eddal jasn\u011b a kr\u00e1tce, ale s takov\u00fdm d\u016frazem na ka\u017ed\u00e9m slov\u011b sv\u00e9 odpov\u011bdi, \u017ee se v\u00e1s najednou \u2014 b\u016fh v\u00ed pro\u010d -zmocnil nep\u0159\u00edjemn\u00fd pocit a kone\u010dn\u011b jste byli sami r\u00e1di, \u017ee je rozhovor skon\u010den. Vyptal jsem se na n\u011bho hned tehdy Ivana Ivanovi\u010de a dov\u011bd\u011bl jsem se, \u017ee Gorjan\u010dikov vede bez\u00fahonn\u00fd, mravn\u00fd \u017eivot, sice by ho Ivan Ivanovi\u010d nevzal za u\u010ditele ke sv\u00fdm dcer\u00e1m; ale \u017ee se hrozn\u011b stran\u00ed spole\u010dnosti, p\u0159ed ka\u017ed\u00fdm se schov\u00e1v\u00e1, je neoby\u010dejn\u011b u\u010den\u00fd, mnoho \u010dte, ale mluv\u00ed velice m\u00e1lo a v\u016fbec \u017ee je dosti obt\u00ed\u017eno d\u00e1ti se s n\u00edm do \u0159e\u010di. N\u011bkte\u0159\u00ed tvrdili, \u017ee je jist\u011b bl\u00e1zen, a\u010dkoli p\u0159ipou\u0161t\u011bli z\u00e1rove\u0148, \u017ee to ve skute\u010dnosti nen\u00ed hrub\u011b d\u016fle\u017eit\u00e1 vada, \u017ee mnoz\u00ed z poctiv\u00fdch soused\u016f m\u011bste\u010dka jsou hotovi prokazovati v\u0161emo\u017enou laskavost Alexandru Petrovi\u010di, \u017ee by dokonce mohl b\u00fdt i u\u017eite\u010dn\u00fdm, \u017ee by na p\u0159\u00edklad mohl spisovati prosebn\u00e9 listy. Dom\u00fd\u0161leli se, \u017ee mus\u00ed m\u00edti v Rusku slu\u0161n\u00e9 p\u0159\u00edbuzenstvo, snad dokonce i lidi, maj\u00edc\u00ed zna\u010dn\u00fd vliv, ale v\u011bd\u011bli, \u017ee od t\u00e9 chv\u00edle, co byl odsouzen k deportaci, p\u0159etrhl rozhodn\u011b v\u0161elik\u00e9 s nimi spo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXt8Na97yRe7",
        "outputId": "0e4ec844-4585-4fc7-9e73-7fe43245af85",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762700527403,
          "user_tz": -60,
          "elapsed": 14,
          "user": {
            "displayName": "Kate\u0159ina V\u00e1lkov\u00e1",
            "userId": "13944778042770891539"
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "D\u00e9lka cel\u00e9ho textu ve znac\u00edch: 2302653\n",
            "Po\u010det v\u011bt: 24401\n",
            "Uk\u00e1zka prvn\u00edch 5 v\u011bt:\n",
            " ['Produced by Miloslav Izar RUSK\u00c1 KNIHOVNA IX.', 'SPISY FEDORA MICHAJLOVI\u010cE DOSTOJEVSK\u00c9HO.', 'P\u0159eklad rediguje JAROM\u00cdR HRUB\u00dd Svazek I.', 'Z\u00c1PISKY Z MRTV\u00c9HO DOMU.', 'P\u0159elo\u017eil H.']\n",
            "Po\u010det chunk\u016f: 1627\n",
            "Uk\u00e1zka prvn\u00edho chunku:\n",
            " Produced by Miloslav Izar RUSK\u00c1 KNIHOVNA IX. SPISY FEDORA MICHAJLOVI\u010cE DOSTOJEVSK\u00c9HO. P\u0159eklad rediguje JAROM\u00cdR HRUB\u00dd Svazek I. Z\u00c1PISKY Z MRTV\u00c9HO DOMU. P\u0159elo\u017eil H. JARO\u0160. V PRAZE 1891. Tiskem a n\u00e1kladem J. Otty. \u010c\u00c1ST PRV\u00c1. \u00daVOD. V dalek\u00fdch kraj\u00edch Sibi\u0159e, uprost\u0159ed step\u00ed, hor a neproniknuteln\u00fdch les\u016f vyskytuj\u00ed se z\u0159\u00eddka malink\u00e1 m\u011bsta s jedn\u00edm nebo nanejv\u00fd\u0161 se dv\u011bma tis\u00edci obyvatel\u016f, d\u0159ev\u011bn\u00e1 to, ne\u00fahledn\u00e1 m\u011bsta se dv\u011bma chr\u00e1my, jedn\u00edm ve m\u011bst\u011b, druh\u00fdm na h\u0159bitov\u011b, a podobn\u00e1 v\u00edce k slu\u0161n\u00e9 vesnici p\n",
            "Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 1627\n",
            "})\n",
            "Prvn\u00ed z\u00e1znam v datasetu:\n",
            " A v Sibi\u0159i j\u00ed u\u017e\u00edvati um\u011bj\u00ed. V jednom z takov\u00fdch vesel\u00fdch, sebou spokojen\u00fdch m\u011bste\u010dek s roztomil\u00fdm obyvatelstvem, jeho\u017e pam\u00e1tka nevymiz\u00ed z m\u00e9ho srdce, setkal jsem se s Alexandrem Petrovi\u010dem Gorjan\u010dikovem, tamn\u00edm osadn\u00edkem, rodil\u00fdm \u0161lechticem a statk\u00e1\u0159em z evropsk\u00e9ho Ruska, odkud\u017e pro vra\u017edu sv\u00e9 \u017eeny byl odesl\u00e1n na Sibi\u0159, kde konal nucen\u00e9 pr\u00e1ce jako trestanec druh\u00e9 t\u0159\u00eddy, a kdy\u017e uplynula z\u00e1konem mu vym\u011b\u0159en\u00e1 desetilet\u00e1 lh\u016fta trestu, stal se osadn\u00edkem ve m\u011bste\u010dku K., kde\u017e pokorn\u011b a ti\u0161e tr\u00e1vil ostatek sv\u00e9ho \u017eivota. Domovsk\u00e9 pr\u00e1vo m\u011bl vlastn\u011b v jedn\u00e9 volosti*), soused\u00edc\u00ed s m\u011bstem, ale bydlel ve m\u011bst\u011b, kde se mu naskytovala mo\u017enost, opat\u0159iti si t\u0159ebas jen skrovnou v\u00fd\u017eivu vyu\u010dov\u00e1n\u00edm d\u011bt\u00ed. V sibi\u0159sk\u00fdch m\u011bstech \u010dasto se setk\u00e1te s u\u010diteli, b\u00fdval\u00fdmi trestanci; jimi nepovrhuj\u00ed. Vyu\u010duj\u00ed hlavn\u011b francouzsk\u00e9mu jazyku, bez n\u011bho\u017e se \u010dlov\u011bk neobejde v b\u011bhu \u017eivota, o n\u011bm\u017e by v\u0161ak bez nich ve vzd\u00e1len\u00fdch kraj\u00edch Sibi\u0159e nem\u011bli ani pon\u011bt\u00ed. Poprv\u00e9 jsem se setkal s Alexandrem Petrovi\u010dem v dom\u011b jist\u00e9ho star\u00e9ho, zaslou\u017eil\u00e9ho a pohostinn\u00e9ho \u00fa\u0159edn\u00edka Ivana Ivanovi\u010de Gvozdikova, jen\u017e m\u011bl p\u011bt velice nad\u011bjn\u00fdch dcer r\u016fzn\u00e9ho st\u00e1\u0159\u00ed. Alexandr Petrovi\u010d jim d\u00e1val hodiny \u010dty\u0159ikr\u00e1t za t\u00fdden, po t\u0159iceti kopejk\u00e1ch st\u0159\u00edbra za hodinu. Jeho zevn\u011bj\u0161ek obr\u00e1til k sob\u011b mou pozornost. Byl to neoby\u010dejn\u011b bled\u00fd, huben\u00fd \u010dlov\u011bk, je\u0161t\u011b ne star\u00fd, asi t\u0159icetip\u011btilet\u00fd, malink\u00fd a slabou\u010dk\u00fd. Oble\u010den b\u00fdval v\u017edycky velmi \u010dist\u011b po evropsku. Dali-li jste se s n\u00edm do \u0159e\u010di, hled\u011bl na v\u00e1s ne- *) Volost\u00ed slov\u011b venkovsk\u00fd, do jist\u00e9 m\u00edry samospr\u00e1vn\u00fd okrsek, s volen\u00fdm starostou a vlastn\u00edm, volen\u00fdm soudem, pod jeho\u017e pravomoc spadaj\u00ed v\u0161ak jen \u010dlenov\u00e9 selsk\u00fdch obc\u00ed. oby\u010dejn\u011b up\u0159en\u011b a pozorn\u011b, s p\u0159\u00edsnou zdvo\u0159ilost\u00ed vyslechl ka\u017ed\u00e9 va\u0161e slovo, jako by se sna\u017eil, vmysliti se v jeho smysl, jako byste mu svou ot\u00e1zkou byli dali h\u00e1danku, anebo se chcete dop\u00e1trati n\u011bkter\u00e9ho jeho tajemstv\u00ed; pak teprv odpov\u00eddal jasn\u011b a kr\u00e1tce, ale s takov\u00fdm d\u016frazem na ka\u017ed\u00e9m slov\u011b sv\u00e9 odpov\u011bdi, \u017ee se v\u00e1s najednou \u2014 b\u016fh v\u00ed pro\u010d -zmocnil nep\u0159\u00edjemn\u00fd pocit a kone\u010dn\u011b jste byli sami r\u00e1di, \u017ee je rozhovor skon\u010den. Vyptal jsem se na n\u011bho hned tehdy Ivana Ivanovi\u010de a dov\u011bd\u011bl jsem se, \u017ee Gorjan\u010dikov vede bez\u00fahonn\u00fd, mravn\u00fd \u017eivot, sice by ho Ivan Ivanovi\u010d nevzal za u\u010ditele ke sv\u00fdm dcer\u00e1m; ale \u017ee se hrozn\u011b stran\u00ed spole\u010dnosti, p\u0159ed ka\u017ed\u00fdm se schov\u00e1v\u00e1, je neoby\u010dejn\u011b u\u010den\u00fd, mnoho \u010dte, ale mluv\u00ed velice m\u00e1lo a v\u016fbec \u017ee je dosti obt\u00ed\u017eno d\u00e1ti se s n\u00edm do \u0159e\u010di. N\u011bkte\u0159\u00ed tvrdili, \u017ee je jist\u011b bl\u00e1zen, a\u010dkoli p\u0159ipou\u0161t\u011bli z\u00e1rove\u0148, \u017ee to ve skute\u010dnosti nen\u00ed hrub\u011b d\u016fle\u017eit\u00e1 vada, \u017ee mnoz\u00ed z poctiv\u00fdch soused\u016f m\u011bste\u010dka jsou hotovi prokazovati v\u0161emo\u017enou laskavost Alexandru Petrovi\u010di, \u017ee by dokonce mohl b\u00fdt i u\u017eite\u010dn\u00fdm, \u017ee by na p\u0159\u00edklad mohl spisovati prosebn\u00e9 listy. Dom\u00fd\u0161leli se, \u017ee mus\u00ed m\u00edti v Rusku slu\u0161n\u00e9 p\u0159\u00edbuzenstvo, snad dokonce i lidi, maj\u00edc\u00ed zna\u010dn\u00fd vliv, ale v\u011bd\u011bli, \u017ee od t\u00e9 chv\u00edle, co byl odsouzen k deportaci, p\u0159etrhl rozhodn\u011b v\u0161elik\u00e9 s nimi spojen\u00ed \u2014 slovem, \u017ee si s\u00e1m \u0161kod\u00ed.<|endoftext|>\n"
          ]
        }
      ],
      "source": [
        "raw_text = re.sub(r\"\\s+\", \" \", raw_text).strip()\n",
        "\n",
        "print(\"D\u00e9lka cel\u00e9ho textu ve znac\u00edch:\", len(raw_text))\n",
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "sentences = re.split(r'(?<=[.!?])\\s+', raw_text)\n",
        "\n",
        "print(\"Po\u010det v\u011bt:\", len(sentences))\n",
        "print(\"Uk\u00e1zka prvn\u00edch 5 v\u011bt:\\n\", sentences[:5])\n",
        "\n",
        "# --- spojov\u00e1n\u00ed v\u011bt do chunk\u016f po 10 v\u011bt\u00e1ch ---\n",
        "chunk_size = 15  # m\u016f\u017ee\u0161 zm\u011bnit na 5 nebo 15 podle pot\u0159eby\n",
        "chunks = [\n",
        "    \" \".join(sentences[i:i + chunk_size])\n",
        "    for i in range(0, len(sentences), chunk_size)\n",
        "    if len(sentences[i:i + chunk_size]) > 0\n",
        "]\n",
        "\n",
        "print(\"Po\u010det chunk\u016f:\", len(chunks))\n",
        "print(\"Uk\u00e1zka prvn\u00edho chunku:\\n\", chunks[0][:500])\n",
        "\n",
        "# --- vytvo\u0159en\u00ed datasetu pro UnSloth ---\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "texts_for_training = [c + EOS_TOKEN for c in chunks]\n",
        "\n",
        "dataset = Dataset.from_dict({\"text\": texts_for_training})\n",
        "print(dataset)\n",
        "print(\"Prvn\u00ed z\u00e1znam v datasetu:\\n\", dataset[2][\"text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idAEIeSQ3xdS"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Continued Pretraining\n",
        "Now let's use Unsloth's `UnslothTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 20 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`.\n",
        "\n",
        "Also set `embedding_learning_rate` to be a learning rate at least 2x or 10x smaller than `learning_rate` to make continual pretraining work!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "43470cc3bf454e4093efd59ad6c2ddb8",
            "8b0abe53b8184fba981446eeb75cafd0",
            "c9c41f94e49449a09f8aed6dd97ae858",
            "63ec81778a124848afa29d13a4c09f8c",
            "113f6545d7bd4bf096965432c3e354ca",
            "01f0873c5d10473e82744b4a5c579083",
            "bfbfec2d102548eeb6865ea41a4d7236",
            "550e03c6ba9e44c2be86d0b2af1cda89",
            "b5d507fbbe5243f6b0e87d6a8c77ac19",
            "890d147ee84d410bbdf383edd0b895b3",
            "6e5e4187a99a40d79a65a81ca6a87835"
          ]
        },
        "id": "95_Nn-89DhsL",
        "outputId": "87c74412-1b52-4fc1-90ba-a808b2df19d1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762700534655,
          "user_tz": -60,
          "elapsed": 3249,
          "user": {
            "displayName": "Kate\u0159ina V\u00e1lkov\u00e1",
            "userId": "13944778042770891539"
          }
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=6):   0%|          | 0/1627 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43470cc3bf454e4093efd59ad6c2ddb8"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import UnslothTrainer, UnslothTrainingArguments\n",
        "\n",
        "trainer = UnslothTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 1,   # sta\u010d\u00ed 1, a\u0165 se to neh\u00e1d\u00e1\n",
        "\n",
        "    args = UnslothTrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 8,\n",
        "\n",
        "        warmup_ratio = 0.02,\n",
        "        num_train_epochs = 3,      # m\u00edsto 100!\n",
        "\n",
        "        learning_rate = 1e-5,      # jemn\u011bj\u0161\u00ed LR\n",
        "        embedding_learning_rate = 1e-6,\n",
        "\n",
        "        logging_steps = 10,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.00,\n",
        "        lr_scheduler_type = \"cosine\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\",\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ejIt2xSNKKp",
        "outputId": "41fe98a0-9136-4cb5-9d6c-6756c150f7a0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762700537482,
          "user_tz": -60,
          "elapsed": 5,
          "user": {
            "displayName": "Kate\u0159ina V\u00e1lkov\u00e1",
            "userId": "13944778042770891539"
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = Tesla T4. Max memory = 14.741 GB.\n",
            "7.941 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "# @title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yqxqAZ7KJ4oL",
        "outputId": "7e10b0cf-4ed1-4a3e-f5ea-2ad776edb3f0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762706937332,
          "user_tz": -60,
          "elapsed": 6398553,
          "user": {
            "displayName": "Kate\u0159ina V\u00e1lkov\u00e1",
            "userId": "13944778042770891539"
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 1,627 | Num Epochs = 3 | Total steps = 306\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 8\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 8 x 1) = 16\n",
            " \"-____-\"     Trainable parameters = 436,076,544 of 4,257,156,096 (10.24% trained)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='306' max='306' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [306/306 1:46:16, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>3.245100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>3.189000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>3.154200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>3.161800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>3.115200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>3.073400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>3.106100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>3.083600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>3.067000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>3.029100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>2.999900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>2.970300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>2.964000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>2.950500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>2.965000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>2.941700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>2.936400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>2.931400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>2.930000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>2.927000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>2.889500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>2.872400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>2.889900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>2.901700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>2.878500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>2.876800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>2.884500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>2.902500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>2.898900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>2.869800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCqnaKmlO1U9",
        "outputId": "95f2dc3b-c776-4ce9-f739-eef74d83701b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762707213048,
          "user_tz": -60,
          "elapsed": 5,
          "user": {
            "displayName": "Kate\u0159ina V\u00e1lkov\u00e1",
            "userId": "13944778042770891539"
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6396.0321 seconds used for training.\n",
            "106.6 minutes used for training.\n",
            "Peak reserved memory = 9.625 GB.\n",
            "Peak reserved memory for training = 1.684 GB.\n",
            "Peak reserved memory % of max memory = 65.294 %.\n",
            "Peak reserved memory for training % of max memory = 11.424 %.\n"
          ]
        }
      ],
      "source": [
        "# @title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory / max_memory * 100, 3)\n",
        "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(\n",
        "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
        ")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekOmTR1hSNcr"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Let's run the model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHm11vaQRt1U",
        "outputId": "04bb2b49-062b-4e8c-d1ab-8b6b4d7386f5",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762707918275,
          "user_tz": -60,
          "elapsed": 49451,
          "user": {
            "displayName": "Kate\u0159ina V\u00e1lkov\u00e1",
            "userId": "13944778042770891539"
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "=== Prompt: \u010clov\u011bk je zvl\u00e1\u0161tn\u00ed tvor, pomyslel si Raskolnikov.  ===\n",
            "\n",
            "\u010clov\u011bk je zvl\u00e1\u0161tn\u00ed tvor, pomyslel si Raskolnikov. \u201aTo jsou \u010dasy!\u2018 podotkl ze \u017eidiny k n\u00e1m p\u0159ece z hlavy: v\u0161ecko bude v\u010dera j\u00edt po sv\u00e9m dom\u00e1c\u00edmu a posl\u00e9ze na v\u011bci p\u0159ednostn\u00e9, ale ve\u010der\u2026 V\u00edte-li, co\u017e jsem st\u00e1le sly\u0161el za okam\u017eik? Ale o tom ho d\u00e1vno nevid\u011bl ani jeden kr\u00e1tkodenn\u00fd m\u016fj mu\u017ee, jak by byl znal jeho v\u00fdsledek i jeho p\u0159\u00edjemnosti, kdy\u017e m\u011bl va\u0161\u00ed dob, kdy se myslil uboh\u00fdm rozumem, \u017ee oni nemaj\u00ed dost pot\u0159ebu proti v\u0161emu! Avtov\u00e1k byl tak zaj\u00edmav\u00fd \u2013 pova\u017eme to je\u0161t\u011b jedin\u00e9, kde m\u00e1me dobr\u00e9ho \u010dasu \u2014 j\u00e1 tu v\u0161ak odpustila pozorov\u00e1n\u00ed. Je mi naprosto pranic, \u017ee proto jsem teprve jako nov\u00e9 \u0161aty p\u0159iznal n\u011bjakou nejrozumn\u011bj\u0161\u00ed, netradi\u010dnou radostnoutu formu; ale tak\u00e9 pak bylo toti\u017e bezpochyby,\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "=== Prompt: \u201eTy tomu nerozum\u00ed\u0161,\u201c \u0159ekl ti\u0161e.  ===\n",
            "\n",
            "\u201eTy tomu nerozum\u00ed\u0161,\u201c \u0159ekl ti\u0161e. \u0158\u00edk\u00e1n\u00ed se tak obt\u011b\u017eoval na rukou k\u016f\u0148i. Byla hned p\u0159ece v n\u011bm jasna a \u010derven\u00e1 tv\u00e1\u0159; o\u010dila se s jak\u00fdmsi dobr\u00fdm sv\u011btlem, jako by ji v\u011bd\u011bl, \u017ee ono je\u0161t\u011b nechci! Vy- skr\u00fdvala si urazn\u011b ke zlo\u010dinu \u2013 kdyby ho byla p\u0159emohena, kdyby to bylo \u0161\u0165astn\u00e9, ale te\u010f m\u011bla chv\u00edli \u00fapln\u011b cel\u00e9 smyslu d\u011bdictv\u00ed a nemohl b\u00fdti mu \u017eivota, nebo\u0165 jest tu vr\u00e1sky pohodln\u00e9ho m\u00edstnosti a m\u00edn\u011bn\u00ed. Ale pak se vlastn\u011b odpov\u011bdi ot\u00e1zky prokladovala i podobnou, kter\u00e1 byly vybuchl\u00e1 trochu p\u0159ed n\u00edm v\u00edc ne\u017e prvn\u00ed. Proto\u017ee jsem tenkr\u00e1t zpr\u00e1vu za\u0159\u00edzen, jedn\u00edm ze mnoh\u00fdch n\u00e1mitk a p\u0159\u00edpad\u016f, v\u0161iml jsem ka\u017ed\u00e9mu jeho slohu: Srdce m\u00e1 citem\u2026 Jest to spozorov\u00e1n\u00ed trestance\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "=== Prompt: R\u00e1no se probudil se zvl\u00e1\u0161tn\u00edm pocitem neklidu. ===\n",
            "\n",
            "R\u00e1no se probudil se zvl\u00e1\u0161tn\u00edm pocitem neklidu. Pro\u010d? M\u011bl t\u00edm zl\u00e9m a z\u00e1le\u017eitostem, proto\u017ee po vzpom\u00ednce pro\u0161lo na jeho krevni \u010dty\u0159i let p\u0159ed \u0159e\u010di u n\u00e1s.\u201c \u201eKone\u010dn\u011b si p\u0159izn\u00e1v\u00e1m;\u201c pokra\u010doval smluviteln\u011b mlad\u00fd d\u011btsk\u00fd jazyk. V t\u00e9 dobu vyj\u00e1d\u0159ila jedinou smyslu: \u017ee jsme se m\u011bli takov\u00fdm zp\u016fsobem, aby on za to hled\u011bly n\u011bjak\u00e9 osobnosti ve sv\u00fdch povah\u00e1ch. Neoby\u010dejn\u00e1 v\u011bc! Nesm\u00ed b\u00fdt p\u0159\u00edmo odpov\u011bdn\u00fd p\u0159i tom, kdy\u017e je potrestan obr\u00e1cen\u00fd a opat\u0159en o v\u0161echny pravdy, kter\u00e9 mu nemaj\u00ed ani pomoc\u00ed vzd\u00e1len\u00e9ho rozmyslu. Zaslouv\u00e1n\u00edm jejich spole\u010dn\u00e9ho poutky st\u00e1le mnoho sn\u00e1\u0161el \u00fapln\u011b n\u00e1ramn\u00fd, chvativ\u00fd v\u00fdraz, kter\u00fd se ji\u017e dosti vyhrbal ze \u0161lechtic\u00edch podobn\u00fdch lid\u00ed, ale tak\u00e9 znamenala siln\u00e9j\u0161\u00edho\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "from transformers import TextIteratorStreamer  # u\u017e vlastn\u011b nepot\u0159ebujeme\n",
        "import torch\n",
        "\n",
        "# p\u0159epnout model do inference re\u017eimu\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "seeds = [\n",
        "    \"\u010clov\u011bk je zvl\u00e1\u0161tn\u00ed tvor, pomyslel si Raskolnikov. \",\n",
        "    \"\u201eTy tomu nerozum\u00ed\u0161,\u201c \u0159ekl ti\u0161e. \",\n",
        "    \"R\u00e1no se probudil se zvl\u00e1\u0161tn\u00edm pocitem neklidu.\",\n",
        "]\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for seed in seeds:\n",
        "    print(f\"\\n\\n=== Prompt: {seed} ===\\n\")\n",
        "\n",
        "    inputs = tokenizer(seed, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens = 256,\n",
        "        do_sample = True,\n",
        "        temperature = 0.8,\n",
        "        top_p = 0.9,\n",
        "        repetition_penalty = 1.1,\n",
        "    )\n",
        "\n",
        "    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    print(text)\n",
        "    print(\"\\n\" + \"-\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## V\u00fdstupy z GPT2 se stejn\u00fdmi prompty\n",
        "\n",
        "=== SEED: '\u010clov\u011bk je zvl\u00e1\u0161tn\u00ed tvor, pomyslel si Raskolnikov. ' ===\n",
        "\n",
        "\u010clov\u011bk je zvl\u00e1\u0161tn\u00ed tvor, pomyslel si Raskolnikov.  Zatracen\u011b  dokud\n",
        "chv\u00edli. \u201eTak, \u017ee jste vrah!\u201c za\u010dal prohl\u00e9dl, \u201e\u017ee tam?\n",
        "\u017ee jsi d\u011bl\u00e1\u0161?\u201c\n",
        "\u201eTo je to v\u0161echno v\u016fbec nept\u00e1v\u00e1m nikoho?\u201c vyhrkl\u00ednal Razumichin.\n",
        "\u201eAle kdy j\u00e1 nevyzpyt?\u201c\n",
        "\u201eJak to ochot\u011b toho nedb\u00e1t ostatn\u011b bytn\u00e1, \u017ee zn\u00e1m\u00fd\u2026 Ano!\u201c\n",
        "\u201eJ\u00e1 nen\u00ed, proto\u017ee vjete jsem m\u011b, m\u016f\u017ee jste se mo\u017en\u00e1 z\u00e1kon-\n",
        "na u\u017e to v\u0161ak v\u00e1s byt\u00edm,\u201c \u0159ekla v n\u011bm, \u201e\u011bm\u017e i nen\u00ed v\u00e1m jste\n",
        "zapomenoutn\u00e9\u2026 jsem jim to tady jen te\u010f, proto\u017ee je tak\u2026 n\u00e1, j\u00e1 jsem se mi\n",
        "mluv\u00edm pravdu\u2026 Tady tady nejv\u00edm, bude nev\u00edm tak p\u0159\u00edmo\u2026\u201c\n",
        "v\u017edy\u0165 jsem za\u010dal, jak skute\u010dn\u011b dopadne rozpak\u016f, ale jsem se dal\n",
        "se to zakrytovat. U\u017e jsem si s n\u00edm j\u00ed za\u010dala, \u017ee\n",
        "tak zahlr\u00e1t \u0159e\u010di\u2026 he\n",
        "\n",
        "=== SEED: '\u201eTy tomu nerozum\u00ed\u0161,\u201c \u0159ekl ti\u0161e. ' ===\n",
        "\n",
        "\u201eTy tomu nerozum\u00ed\u0161,\u201c \u0159ekl ti\u0161e.  \u201eKdo v\u011bci  v\u00e1m  \u017ee  u\u017e  n\u00e1le\u017eitost  odpu\u0161t\u011bv,\n",
        "proto\u017ee se\u0161el o\u010di. Zkr\u00e1til jeden s takov\u00fdm p\u0159\u00edmo po \u010dern\u00e9m\n",
        "a p\u0159esv\u011bd\u010den\u00edm a kapsy si na to. A proto\u017ee si opravd\u00ed se tak p\u0159\u00edli\u0161\n",
        "dokonce n\u00e1hle za n\u011bco p\u0159\u00edtati, o \u010demu si pro mne p\u0159ijdu.\n",
        "\u201eNebude sv\u00fdch se neb\u00fdt za d\u00e1vno,\u201c \u0159ekl Raskolnikov. \u201eKdybych si v\u0161ak nem\u011bl! Jsem\n",
        "dobr mou du\u0161evn\u011b.\u201c\n",
        "\u201eA ty jsem \u0159ekl, \u017ee jsem vzpomn\u011bl jsem p\u0159esv\u011bd\u010den,\u201c po-\n",
        "chin, \u201ejak jsem tak zvalo, \u017ee hned po\u010dal,\u201c uml\u010del na ni z\u00e1-\n",
        "m\u00edsta obt\u00edm ned\u00e1 t\u0159eje a s netrp\u011bliv\u011b Ivanovn\u011b odhalen\u011b ze\n",
        "n\u00e1v\u00e1, kterou jsem tak \u0159ekl, \u017ee jsem se to \u0159\u00edk\u00e1val, \u017ee se\n",
        "u\u017e ho \u0159\u00edk\u00e1m, \u017ee by mu to p\u0159edt\u00edm.\u201c\n",
        "\u201eNo, v\n",
        "\n",
        "=== SEED: 'R\u00e1no se probudil se zvl\u00e1\u0161tn\u00edm pocitem neklidu.' ===\n",
        "\n",
        "R\u00e1no se probudil se zvl\u00e1\u0161tn\u00edm pocitem neklidu. Ostatn\u011b bylo mo\u017eno st\u00e1ti. A vyskytl si dokonce nejv\u00edce buldru\u0161\u00edm o tom, \u017ee se zd\u00e1lo, \u017ee se mu rozd\u00e1lo: opakoval, \u017ee sna\u017eil na m\u00edsta, tak takov\u00e1 v\u011bzn\u011bs\u00edce. U\u017e nen\u00ed nic nikterak nepros\u00edce nevad\u00ed. Zde mn\u011b dopust\u00edm vyhled\u00e1val se, \u017ee ji porozum\u00ed, m\u00e1lo pro tebe, a bylo p\u0159edstaviti, co se obl\u00e9k\u00e1vati. Zd\u00e1 se, \u017ee bylo za to, co tak j\u00e1, \u017ee nemo\u017en\u00e1 dosti p\u0159edstaven\u00ed prostran\u00ed, aby se v\u0161ak s\u00edlu\u0161\u00edm v\u00e1s velik\u00fdch a skoro sm\u011b\u0161nost\u00ed, a \u017ee jsem s\u00e1m p\u0159edstavenstvo. Zde on s\u00e1m s n\u00e1m v nemocnic\u00ed. \u017d...sk\u00fd trestanci, za narazil jsem \u00fapln\u011b dva zapomn\u011bl. Ale v\u00e1\u0161eli, \u017ee pan Goljadkin mlad\u0161\u00ed s\u00edla na jevo, n\u00e1hle se nazpokojila s podnik, jakoby byl v\u011bdom vlastn\u011b spolehliv\u00e9 sluha, kter\u00e9 nemohu po\u010d\u00ednalo se mn\u011b s nimi\u017e mysli. \u201eAno, \ufffd\n"
      ],
      "metadata": {
        "id": "rNS7bl_2lki6"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [
        {
          "file_id": "1VUCKGqnxFtAivLWEdA8W9V2cOIlUIqiX",
          "timestamp": 1762629809141
        },
        {
          "file_id": "14YUvZuog7dNBFUWLZDv8ttl2i1VvW1fO",
          "timestamp": 1762445538835
        },
        {
          "file_id": "https://github.com/unslothai/notebooks/blob/main/nb/Mistral_(7B)-Text_Completion.ipynb",
          "timestamp": 1762345310397
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}